<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>K8s-kubelet(Pod生命周期管理) | Joohwan</title><meta name="author" content="Joohwan."><meta name="copyright" content="Joohwan."><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="K8s-kubelet(Pod生命周期管理) 基于1.25  kubelet以Pod为基本处理单元，负责Pod从创建到消亡的整个生命周期   在1.21中Unknown状态已经被标记为弃用。  CRIkubelet通过CRI RPC管理容器的生命周期，执行容器的lifecycle hook和 startup&#x2F;liveness&#x2F;readiness的健康检查，同时根据Pod的重启策">
<meta property="og:type" content="article">
<meta property="og:title" content="K8s-kubelet(Pod生命周期管理)">
<meta property="og:url" content="https://piwriw.github.io/2024/12/13/cloud/k8s/kubelet/K8s-kubelet(Pod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86)/index.html">
<meta property="og:site_name" content="Joohwan">
<meta property="og:description" content="K8s-kubelet(Pod生命周期管理) 基于1.25  kubelet以Pod为基本处理单元，负责Pod从创建到消亡的整个生命周期   在1.21中Unknown状态已经被标记为弃用。  CRIkubelet通过CRI RPC管理容器的生命周期，执行容器的lifecycle hook和 startup&#x2F;liveness&#x2F;readiness的健康检查，同时根据Pod的重启策">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://piwriw.github.io/img/k8sLogo.png">
<meta property="article:published_time" content="2024-12-13T14:22:55.000Z">
<meta property="article:modified_time" content="2025-08-24T14:17:08.269Z">
<meta property="article:author" content="Joohwan.">
<meta property="article:tag" content="k8s">
<meta property="article:tag" content="cloud">
<meta property="article:tag" content="K8s源码">
<meta property="article:tag" content="kubelet">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://piwriw.github.io/img/k8sLogo.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "K8s-kubelet(Pod生命周期管理)",
  "url": "https://piwriw.github.io/2024/12/13/cloud/k8s/kubelet/K8s-kubelet(Pod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86)/",
  "image": "https://piwriw.github.io/img/k8sLogo.png",
  "datePublished": "2024-12-13T14:22:55.000Z",
  "dateModified": "2025-08-24T14:17:08.269Z",
  "author": [
    {
      "@type": "Person",
      "name": "Joohwan.",
      "url": "https://github.com/Piwriw"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://piwriw.github.io/2024/12/13/cloud/k8s/kubelet/K8s-kubelet(Pod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86)/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'K8s-kubelet(Pod生命周期管理)',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script src="/js/welcome.js"></script><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">245</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">75</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">59</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/charts/"><i class="fa-fw fas fa-folder-open"></i><span> 文章统计</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/wish/"><i class="fa-fw fas fa-tags"></i><span> 许愿墙</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/k8sLogo.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Joohwan</span></a><a class="nav-page-title" href="/"><span class="site-name">K8s-kubelet(Pod生命周期管理)</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/charts/"><i class="fa-fw fas fa-folder-open"></i><span> 文章统计</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/wish/"><i class="fa-fw fas fa-tags"></i><span> 许愿墙</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">K8s-kubelet(Pod生命周期管理)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-13T14:22:55.000Z" title="发表于 2024-12-13 22:22:55">2024-12-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-24T14:17:08.269Z" title="更新于 2025-08-24 22:17:08">2025-08-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/cloud/">cloud</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/cloud/k8s/">k8s</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/cloud/k8s/kubelet/">kubelet</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">12.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>68分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;It has been&quot;,&quot;messageNext&quot;:&quot;days since the last update, the content of the article may be outdated.&quot;,&quot;postUpdate&quot;:&quot;2025-08-24 22:17:08&quot;}" hidden></div><h1 id="K8s-kubelet-Pod生命周期管理"><a href="#K8s-kubelet-Pod生命周期管理" class="headerlink" title="K8s-kubelet(Pod生命周期管理)"></a>K8s-kubelet(Pod生命周期管理)</h1><blockquote>
<p>基于1.25</p>
</blockquote>
<p>kubelet以Pod为基本处理单元，负责Pod从创建到消亡的整个生命周期</p>
<p><img src="https://raw.githubusercontent.com/Piwriw/PicGo/master/image202412132252906.png"></p>
<blockquote>
<p>在1.21中Unknown状态已经被标记为弃用。</p>
</blockquote>
<h2 id="CRI"><a href="#CRI" class="headerlink" title="CRI"></a>CRI</h2><p>kubelet通过CRI RPC管理容器的生命周期，执行容器的lifecycle hook和 startup&#x2F;liveness&#x2F;readiness的健康检查，同时根据Pod的重启策略在容器失败退出后自动重启容器，CRI是kubelet管理Pod和容器的基础</p>
<p><img src="https://raw.githubusercontent.com/Piwriw/PicGo/master/image202412132303554.png"></p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/cri-api/blob/2c8d015e0d408208ca8843c1d6e2e2fce1e5dd94/pkg/apis/runtime/v1/api.proto#L34">https://github.com/kubernetes/cri-api/blob/2c8d015e0d408208ca8843c1d6e2e2fce1e5dd94/pkg/apis/runtime/v1/api.proto#L34</a></p>
<figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Runtime service defines the public APIs for remote container runtimes</span></span><br><span class="line"><span class="keyword">service </span><span class="title class_">RuntimeService</span> &#123;</span><br><span class="line">    <span class="comment">// Version returns the runtime name, runtime version, and runtime API version.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> Version(VersionRequest) <span class="keyword">returns</span> (VersionResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// RunPodSandbox creates and starts a pod-level sandbox. Runtimes must ensure</span></span><br><span class="line">    <span class="comment">// the sandbox is in the ready state on success.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> RunPodSandbox(RunPodSandboxRequest) <span class="keyword">returns</span> (RunPodSandboxResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// StopPodSandbox stops any running process that is part of the sandbox and</span></span><br><span class="line">    <span class="comment">// reclaims network resources (e.g., IP addresses) allocated to the sandbox.</span></span><br><span class="line">    <span class="comment">// If there are any running containers in the sandbox, they must be forcibly</span></span><br><span class="line">    <span class="comment">// terminated.</span></span><br><span class="line">    <span class="comment">// This call is idempotent, and must not return an error if all relevant</span></span><br><span class="line">    <span class="comment">// resources have already been reclaimed. kubelet will call StopPodSandbox</span></span><br><span class="line">    <span class="comment">// at least once before calling RemovePodSandbox. It will also attempt to</span></span><br><span class="line">    <span class="comment">// reclaim resources eagerly, as soon as a sandbox is not needed. Hence,</span></span><br><span class="line">    <span class="comment">// multiple StopPodSandbox calls are expected.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> StopPodSandbox(StopPodSandboxRequest) <span class="keyword">returns</span> (StopPodSandboxResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// RemovePodSandbox removes the sandbox. If there are any running containers</span></span><br><span class="line">    <span class="comment">// in the sandbox, they must be forcibly terminated and removed.</span></span><br><span class="line">    <span class="comment">// This call is idempotent, and must not return an error if the sandbox has</span></span><br><span class="line">    <span class="comment">// already been removed.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> RemovePodSandbox(RemovePodSandboxRequest) <span class="keyword">returns</span> (RemovePodSandboxResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// PodSandboxStatus returns the status of the PodSandbox. If the PodSandbox is not</span></span><br><span class="line">    <span class="comment">// present, returns an error.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> PodSandboxStatus(PodSandboxStatusRequest) <span class="keyword">returns</span> (PodSandboxStatusResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// ListPodSandbox returns a list of PodSandboxes.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ListPodSandbox(ListPodSandboxRequest) <span class="keyword">returns</span> (ListPodSandboxResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// CreateContainer creates a new container in specified PodSandbox</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> CreateContainer(CreateContainerRequest) <span class="keyword">returns</span> (CreateContainerResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// StartContainer starts the container.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> StartContainer(StartContainerRequest) <span class="keyword">returns</span> (StartContainerResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// StopContainer stops a running container with a grace period (i.e., timeout).</span></span><br><span class="line">    <span class="comment">// This call is idempotent, and must not return an error if the container has</span></span><br><span class="line">    <span class="comment">// already been stopped.</span></span><br><span class="line">    <span class="comment">// The runtime must forcibly kill the container after the grace period is</span></span><br><span class="line">    <span class="comment">// reached.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> StopContainer(StopContainerRequest) <span class="keyword">returns</span> (StopContainerResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// RemoveContainer removes the container. If the container is running, the</span></span><br><span class="line">    <span class="comment">// container must be forcibly removed.</span></span><br><span class="line">    <span class="comment">// This call is idempotent, and must not return an error if the container has</span></span><br><span class="line">    <span class="comment">// already been removed.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> RemoveContainer(RemoveContainerRequest) <span class="keyword">returns</span> (RemoveContainerResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// ListContainers lists all containers by filters.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ListContainers(ListContainersRequest) <span class="keyword">returns</span> (ListContainersResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// ContainerStatus returns status of the container. If the container is not</span></span><br><span class="line">    <span class="comment">// present, returns an error.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ContainerStatus(ContainerStatusRequest) <span class="keyword">returns</span> (ContainerStatusResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// UpdateContainerResources updates ContainerConfig of the container synchronously.</span></span><br><span class="line">    <span class="comment">// If runtime fails to transactionally update the requested resources, an error is returned.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> UpdateContainerResources(UpdateContainerResourcesRequest) <span class="keyword">returns</span> (UpdateContainerResourcesResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// ReopenContainerLog asks runtime to reopen the stdout/stderr log file</span></span><br><span class="line">    <span class="comment">// for the container. This is often called after the log file has been</span></span><br><span class="line">    <span class="comment">// rotated. If the container is not running, container runtime can choose</span></span><br><span class="line">    <span class="comment">// to either create a new log file and return nil, or return an error.</span></span><br><span class="line">    <span class="comment">// Once it returns error, new container log file MUST NOT be created.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ReopenContainerLog(ReopenContainerLogRequest) <span class="keyword">returns</span> (ReopenContainerLogResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ExecSync runs a command in a container synchronously.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ExecSync(ExecSyncRequest) <span class="keyword">returns</span> (ExecSyncResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// Exec prepares a streaming endpoint to execute a command in the container.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> Exec(ExecRequest) <span class="keyword">returns</span> (ExecResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// Attach prepares a streaming endpoint to attach to a running container.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> Attach(AttachRequest) <span class="keyword">returns</span> (AttachResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// PortForward prepares a streaming endpoint to forward ports from a PodSandbox.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> PortForward(PortForwardRequest) <span class="keyword">returns</span> (PortForwardResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ContainerStats returns stats of the container. If the container does not</span></span><br><span class="line">    <span class="comment">// exist, the call returns an error.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ContainerStats(ContainerStatsRequest) <span class="keyword">returns</span> (ContainerStatsResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// ListContainerStats returns stats of all running containers.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ListContainerStats(ListContainerStatsRequest) <span class="keyword">returns</span> (ListContainerStatsResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// PodSandboxStats returns stats of the pod sandbox. If the pod sandbox does not</span></span><br><span class="line">    <span class="comment">// exist, the call returns an error.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> PodSandboxStats(PodSandboxStatsRequest) <span class="keyword">returns</span> (PodSandboxStatsResponse) </span>&#123;&#125;</span><br><span class="line">    <span class="comment">// ListPodSandboxStats returns stats of the pod sandboxes matching a filter.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> ListPodSandboxStats(ListPodSandboxStatsRequest) <span class="keyword">returns</span> (ListPodSandboxStatsResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// UpdateRuntimeConfig updates the runtime configuration based on the given request.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> UpdateRuntimeConfig(UpdateRuntimeConfigRequest) <span class="keyword">returns</span> (UpdateRuntimeConfigResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Status returns the status of the runtime.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> Status(StatusRequest) <span class="keyword">returns</span> (StatusResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// CheckpointContainer checkpoints a container</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> CheckpointContainer(CheckpointContainerRequest) <span class="keyword">returns</span> (CheckpointContainerResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// GetContainerEvents gets container events from the CRI runtime</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span>  GetContainerEvents(GetEventsRequest) <span class="keyword">returns</span> (stream ContainerEventResponse) </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Pod启动流程"><a href="#Pod启动流程" class="headerlink" title="Pod启动流程"></a>Pod启动流程</h2><h3 id="syncLoop监听到Pod创建事件，触发执行HandlerPodAdditions-Handler"><a href="#syncLoop监听到Pod创建事件，触发执行HandlerPodAdditions-Handler" class="headerlink" title="syncLoop监听到Pod创建事件，触发执行HandlerPodAdditions Handler"></a>syncLoop监听到Pod创建事件，触发执行HandlerPodAdditions Handler</h3><p>kubelet最终会启动一个sync主调谐程序，最终他们都触发执行syncLoopIteration，执行HandlerPodAdditions，将任务下发给podWorkers异步执行</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/config/apiserver.go#L37">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/config/apiserver.go#L37</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NewSourceApiserver creates a config source that watches and pulls from the apiserver.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewSourceApiserver</span><span class="params">(c clientset.Interface, nodeName types.NodeName, nodeHasSynced <span class="keyword">func</span>()</span></span> <span class="type">bool</span>, updates <span class="keyword">chan</span>&lt;- <span class="keyword">interface</span>&#123;&#125;) &#123;</span><br><span class="line">	lw := cache.NewListWatchFromClient(c.CoreV1().RESTClient(), <span class="string">&quot;pods&quot;</span>, metav1.NamespaceAll, fields.OneTermEqualSelector(<span class="string">&quot;spec.nodeName&quot;</span>, <span class="type">string</span>(nodeName)))</span><br><span class="line"></span><br><span class="line">	<span class="comment">// The Reflector responsible for watching pods at the apiserver should be run only after</span></span><br><span class="line">	<span class="comment">// the node sync with the apiserver has completed.</span></span><br><span class="line">	klog.InfoS(<span class="string">&quot;Waiting for node sync before watching apiserver pods&quot;</span>)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">for</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> nodeHasSynced() &#123;</span><br><span class="line">				klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;node sync completed&quot;</span>)</span><br><span class="line">				<span class="keyword">break</span></span><br><span class="line">			&#125;</span><br><span class="line">			time.Sleep(WaitForAPIServerSyncPeriod)</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;node sync has not completed yet&quot;</span>)</span><br><span class="line">		&#125;</span><br><span class="line">		klog.InfoS(<span class="string">&quot;Watching apiserver&quot;</span>)</span><br><span class="line">		newSourceApiserverFromLW(lw, updates)</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>NewSourceApiserver 负责创建kube-apiserver事件监听源。此处通过设置fieldSelector确保收到的Pod仅于本节点相关，即Pod的spec.nodeName必须和当前的kubelet设置的nodeName匹配，才能接受并处理。</p>
<ul>
<li>在收到Pod事件后，通过Reflector的Store存储接口设置为send，来实现将Event直接发送到updates Channel</li>
</ul>
<p>来自不同的事件源的Event首先会被PodConfig做Merge聚合处理，同时确保事件按照正确的顺序推送给syncLoopIteration</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/config/config.go#L212">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/config/config.go#L212</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *podStorage)</span></span> merge(source <span class="type">string</span>, change <span class="keyword">interface</span>&#123;&#125;) (adds, updates, deletes, removes, reconciles *kubetypes.PodUpdate) &#123;</span><br><span class="line">	s.podLock.Lock()</span><br><span class="line">	<span class="keyword">defer</span> s.podLock.Unlock()</span><br><span class="line"></span><br><span class="line">	addPods := []*v1.Pod&#123;&#125;</span><br><span class="line">	updatePods := []*v1.Pod&#123;&#125;</span><br><span class="line">	deletePods := []*v1.Pod&#123;&#125;</span><br><span class="line">	removePods := []*v1.Pod&#123;&#125;</span><br><span class="line">	reconcilePods := []*v1.Pod&#123;&#125;</span><br><span class="line"></span><br><span class="line">	pods := s.pods[source]</span><br><span class="line">	<span class="keyword">if</span> pods == <span class="literal">nil</span> &#123;</span><br><span class="line">		pods = <span class="built_in">make</span>(<span class="keyword">map</span>[types.UID]*v1.Pod)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// updatePodFunc is the local function which updates the pod cache *oldPods* with new pods *newPods*.</span></span><br><span class="line">	<span class="comment">// After updated, new pod will be stored in the pod cache *pods*.</span></span><br><span class="line">	<span class="comment">// Notice that *pods* and *oldPods* could be the same cache.</span></span><br><span class="line">	updatePodsFunc := <span class="function"><span class="keyword">func</span><span class="params">(newPods []*v1.Pod, oldPods, pods <span class="keyword">map</span>[types.UID]*v1.Pod)</span></span> &#123;</span><br><span class="line">		filtered := filterInvalidPods(newPods, source, s.recorder)</span><br><span class="line">		<span class="keyword">for</span> _, ref := <span class="keyword">range</span> filtered &#123;</span><br><span class="line">			<span class="comment">// Annotate the pod with the source before any comparison.</span></span><br><span class="line">			<span class="keyword">if</span> ref.Annotations == <span class="literal">nil</span> &#123;</span><br><span class="line">				ref.Annotations = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>)</span><br><span class="line">			&#125;</span><br><span class="line">			ref.Annotations[kubetypes.ConfigSourceAnnotationKey] = source</span><br><span class="line">			<span class="keyword">if</span> existing, found := oldPods[ref.UID]; found &#123;</span><br><span class="line">				pods[ref.UID] = existing</span><br><span class="line">				needUpdate, needReconcile, needGracefulDelete := checkAndUpdatePod(existing, ref)</span><br><span class="line">				<span class="keyword">if</span> needUpdate &#123;</span><br><span class="line">					updatePods = <span class="built_in">append</span>(updatePods, existing)</span><br><span class="line">				&#125; <span class="keyword">else</span> <span class="keyword">if</span> needReconcile &#123;</span><br><span class="line">					reconcilePods = <span class="built_in">append</span>(reconcilePods, existing)</span><br><span class="line">				&#125; <span class="keyword">else</span> <span class="keyword">if</span> needGracefulDelete &#123;</span><br><span class="line">					deletePods = <span class="built_in">append</span>(deletePods, existing)</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			recordFirstSeenTime(ref)</span><br><span class="line">			pods[ref.UID] = ref</span><br><span class="line">			addPods = <span class="built_in">append</span>(addPods, ref)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	update := change.(kubetypes.PodUpdate)</span><br><span class="line">	<span class="keyword">switch</span> update.Op &#123;</span><br><span class="line">	<span class="keyword">case</span> kubetypes.ADD, kubetypes.UPDATE, kubetypes.DELETE:</span><br><span class="line">		<span class="keyword">if</span> update.Op == kubetypes.ADD &#123;</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Adding new pods from source&quot;</span>, <span class="string">&quot;source&quot;</span>, source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(update.Pods))</span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> update.Op == kubetypes.DELETE &#123;</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Gracefully deleting pods from source&quot;</span>, <span class="string">&quot;source&quot;</span>, source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(update.Pods))</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Updating pods from source&quot;</span>, <span class="string">&quot;source&quot;</span>, source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(update.Pods))</span><br><span class="line">		&#125;</span><br><span class="line">		updatePodsFunc(update.Pods, pods, pods)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">case</span> kubetypes.REMOVE:</span><br><span class="line">		klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Removing pods from source&quot;</span>, <span class="string">&quot;source&quot;</span>, source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(update.Pods))</span><br><span class="line">		<span class="keyword">for</span> _, value := <span class="keyword">range</span> update.Pods &#123;</span><br><span class="line">			<span class="keyword">if</span> existing, found := pods[value.UID]; found &#123;</span><br><span class="line">				<span class="comment">// this is a delete</span></span><br><span class="line">				<span class="built_in">delete</span>(pods, value.UID)</span><br><span class="line">				removePods = <span class="built_in">append</span>(removePods, existing)</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// this is a no-op</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">case</span> kubetypes.SET:</span><br><span class="line">		klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Setting pods for source&quot;</span>, <span class="string">&quot;source&quot;</span>, source)</span><br><span class="line">		s.markSourceSet(source)</span><br><span class="line">		<span class="comment">// Clear the old map entries by just creating a new map</span></span><br><span class="line">		oldPods := pods</span><br><span class="line">		pods = <span class="built_in">make</span>(<span class="keyword">map</span>[types.UID]*v1.Pod)</span><br><span class="line">		updatePodsFunc(update.Pods, oldPods, pods)</span><br><span class="line">		<span class="keyword">for</span> uid, existing := <span class="keyword">range</span> oldPods &#123;</span><br><span class="line">			<span class="keyword">if</span> _, found := pods[uid]; !found &#123;</span><br><span class="line">				<span class="comment">// this is a delete</span></span><br><span class="line">				removePods = <span class="built_in">append</span>(removePods, existing)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		klog.InfoS(<span class="string">&quot;Received invalid update type&quot;</span>, <span class="string">&quot;type&quot;</span>, update)</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	s.pods[source] = pods</span><br><span class="line"></span><br><span class="line">	adds = &amp;kubetypes.PodUpdate&#123;Op: kubetypes.ADD, Pods: copyPods(addPods), Source: source&#125;</span><br><span class="line">	updates = &amp;kubetypes.PodUpdate&#123;Op: kubetypes.UPDATE, Pods: copyPods(updatePods), Source: source&#125;</span><br><span class="line">	deletes = &amp;kubetypes.PodUpdate&#123;Op: kubetypes.DELETE, Pods: copyPods(deletePods), Source: source&#125;</span><br><span class="line">	removes = &amp;kubetypes.PodUpdate&#123;Op: kubetypes.REMOVE, Pods: copyPods(removePods), Source: source&#125;</span><br><span class="line">	reconciles = &amp;kubetypes.PodUpdate&#123;Op: kubetypes.RECONCILE, Pods: copyPods(reconcilePods), Source: source&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> adds, updates, deletes, removes, reconciles</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>PodConfig通过内部的Cache已经发现的Pod，当有change的事件，通过对比新老数据，判断Pod事件分为ADD、UPDATE、DELETE、REMOVE、RECONFILE几种</p>
<p>syncLoopIeration处理并处理PodUpdate事件</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2083">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2083</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span></span> syncLoopIteration(configCh &lt;-<span class="keyword">chan</span> kubetypes.PodUpdate, handler SyncHandler,</span><br><span class="line">	syncCh &lt;-<span class="keyword">chan</span> time.Time, housekeepingCh &lt;-<span class="keyword">chan</span> time.Time, plegCh &lt;-<span class="keyword">chan</span> *pleg.PodLifecycleEvent) <span class="type">bool</span> &#123;</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> u, open := &lt;-configCh:</span><br><span class="line">		<span class="comment">// Update from a config source; dispatch it to the right handler</span></span><br><span class="line">		<span class="comment">// callback.</span></span><br><span class="line">		<span class="keyword">if</span> !open &#123;</span><br><span class="line">			klog.ErrorS(<span class="literal">nil</span>, <span class="string">&quot;Update channel is closed, exiting the sync loop&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">switch</span> u.Op &#123;</span><br><span class="line">		<span class="keyword">case</span> kubetypes.ADD:</span><br><span class="line">			klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;SyncLoop ADD&quot;</span>, <span class="string">&quot;source&quot;</span>, u.Source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(u.Pods))</span><br><span class="line">			<span class="comment">// After restarting, kubelet will get all existing pods through</span></span><br><span class="line">			<span class="comment">// ADD as if they are new pods. These pods will then go through the</span></span><br><span class="line">			<span class="comment">// admission process and *may* be rejected. This can be resolved</span></span><br><span class="line">			<span class="comment">// once we have checkpointing.</span></span><br><span class="line">			handler.HandlePodAdditions(u.Pods)</span><br><span class="line">		<span class="keyword">case</span> kubetypes.UPDATE:</span><br><span class="line">			klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;SyncLoop UPDATE&quot;</span>, <span class="string">&quot;source&quot;</span>, u.Source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(u.Pods))</span><br><span class="line">			handler.HandlePodUpdates(u.Pods)</span><br><span class="line">		<span class="keyword">case</span> kubetypes.REMOVE:</span><br><span class="line">			klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;SyncLoop REMOVE&quot;</span>, <span class="string">&quot;source&quot;</span>, u.Source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(u.Pods))</span><br><span class="line">			handler.HandlePodRemoves(u.Pods)</span><br><span class="line">		<span class="keyword">case</span> kubetypes.RECONCILE:</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;SyncLoop RECONCILE&quot;</span>, <span class="string">&quot;source&quot;</span>, u.Source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(u.Pods))</span><br><span class="line">			handler.HandlePodReconcile(u.Pods)</span><br><span class="line">		<span class="keyword">case</span> kubetypes.DELETE:</span><br><span class="line">			klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;SyncLoop DELETE&quot;</span>, <span class="string">&quot;source&quot;</span>, u.Source, <span class="string">&quot;pods&quot;</span>, klog.KObjs(u.Pods))</span><br><span class="line">			<span class="comment">// DELETE is treated as a UPDATE because of graceful deletion.</span></span><br><span class="line">			handler.HandlePodUpdates(u.Pods)</span><br><span class="line">		<span class="keyword">case</span> kubetypes.SET:</span><br><span class="line">			<span class="comment">// <span class="doctag">TODO:</span> Do we want to support this?</span></span><br><span class="line">			klog.ErrorS(<span class="literal">nil</span>, <span class="string">&quot;Kubelet does not support snapshot update&quot;</span>)</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			klog.ErrorS(<span class="literal">nil</span>, <span class="string">&quot;Invalid operation type received&quot;</span>, <span class="string">&quot;operation&quot;</span>, u.Op)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		kl.sourcesReady.AddSource(u.Source)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">case</span> e := &lt;-plegCh:</span><br><span class="line">		<span class="keyword">if</span> e.Type == pleg.ContainerStarted &#123;</span><br><span class="line">			<span class="comment">// record the most recent time we observed a container start for this pod.</span></span><br><span class="line">			<span class="comment">// this lets us selectively invalidate the runtimeCache when processing a delete for this pod</span></span><br><span class="line">			<span class="comment">// to make sure we don&#x27;t miss handling graceful termination for containers we reported as having started.</span></span><br><span class="line">			kl.lastContainerStartedTime.Add(e.ID, time.Now())</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> isSyncPodWorthy(e) &#123;</span><br><span class="line">			<span class="comment">// PLEG event for a pod; sync it.</span></span><br><span class="line">			<span class="keyword">if</span> pod, ok := kl.podManager.GetPodByUID(e.ID); ok &#123;</span><br><span class="line">				klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;SyncLoop (PLEG): event for pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;event&quot;</span>, e)</span><br><span class="line">				handler.HandlePodSyncs([]*v1.Pod&#123;pod&#125;)</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="comment">// If the pod no longer exists, ignore the event.</span></span><br><span class="line">				klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;SyncLoop (PLEG): pod does not exist, ignore irrelevant event&quot;</span>, <span class="string">&quot;event&quot;</span>, e)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> e.Type == pleg.ContainerDied &#123;</span><br><span class="line">			<span class="keyword">if</span> containerID, ok := e.Data.(<span class="type">string</span>); ok &#123;</span><br><span class="line">				kl.cleanUpContainersInPod(e.ID, containerID)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">case</span> &lt;-syncCh:</span><br><span class="line">		<span class="comment">// Sync pods waiting for sync</span></span><br><span class="line">		podsToSync := kl.getPodsToSync()</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">len</span>(podsToSync) == <span class="number">0</span> &#123;</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">		klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;SyncLoop (SYNC) pods&quot;</span>, <span class="string">&quot;total&quot;</span>, <span class="built_in">len</span>(podsToSync), <span class="string">&quot;pods&quot;</span>, klog.KObjs(podsToSync))</span><br><span class="line">		handler.HandlePodSyncs(podsToSync)</span><br><span class="line">	<span class="keyword">case</span> update := &lt;-kl.livenessManager.Updates():</span><br><span class="line">		<span class="keyword">if</span> update.Result == proberesults.Failure &#123;</span><br><span class="line">			handleProbeSync(kl, update, handler, <span class="string">&quot;liveness&quot;</span>, <span class="string">&quot;unhealthy&quot;</span>)</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">case</span> update := &lt;-kl.readinessManager.Updates():</span><br><span class="line">		ready := update.Result == proberesults.Success</span><br><span class="line">		kl.statusManager.SetContainerReadiness(update.PodUID, update.ContainerID, ready)</span><br><span class="line"></span><br><span class="line">		status := <span class="string">&quot;&quot;</span></span><br><span class="line">		<span class="keyword">if</span> ready &#123;</span><br><span class="line">			status = <span class="string">&quot;ready&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">		handleProbeSync(kl, update, handler, <span class="string">&quot;readiness&quot;</span>, status)</span><br><span class="line">	<span class="keyword">case</span> update := &lt;-kl.startupManager.Updates():</span><br><span class="line">		started := update.Result == proberesults.Success</span><br><span class="line">		kl.statusManager.SetContainerStartup(update.PodUID, update.ContainerID, started)</span><br><span class="line"></span><br><span class="line">		status := <span class="string">&quot;unhealthy&quot;</span></span><br><span class="line">		<span class="keyword">if</span> started &#123;</span><br><span class="line">			status = <span class="string">&quot;started&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">		handleProbeSync(kl, update, handler, <span class="string">&quot;startup&quot;</span>, status)</span><br><span class="line">	<span class="keyword">case</span> &lt;-housekeepingCh:</span><br><span class="line">		<span class="keyword">if</span> !kl.sourcesReady.AllReady() &#123;</span><br><span class="line">			<span class="comment">// If the sources aren&#x27;t ready or volume manager has not yet synced the states,</span></span><br><span class="line">			<span class="comment">// skip housekeeping, as we may accidentally delete pods from unready sources.</span></span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;SyncLoop (housekeeping, skipped): sources aren&#x27;t ready yet&quot;</span>)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			start := time.Now()</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;SyncLoop (housekeeping)&quot;</span>)</span><br><span class="line">			<span class="keyword">if</span> err := handler.HandlePodCleanups(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">				klog.ErrorS(err, <span class="string">&quot;Failed cleaning pods&quot;</span>)</span><br><span class="line">			&#125;</span><br><span class="line">			duration := time.Since(start)</span><br><span class="line">			<span class="keyword">if</span> duration &gt; housekeepingWarningDuration &#123;</span><br><span class="line">				klog.ErrorS(fmt.Errorf(<span class="string">&quot;housekeeping took too long&quot;</span>), <span class="string">&quot;Housekeeping took longer than 15s&quot;</span>, <span class="string">&quot;seconds&quot;</span>, duration.Seconds())</span><br><span class="line">			&#125;</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;SyncLoop (housekeeping) end&quot;</span>)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>新建Pod对应的ADD事件，直接由HandlePodAdditions处理</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2238">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2238</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// HandlePodAdditions is the callback in SyncHandler for pods being added from</span></span><br><span class="line"><span class="comment">// a config source.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span></span> HandlePodAdditions(pods []*v1.Pod) &#123;</span><br><span class="line">	start := kl.clock.Now()</span><br><span class="line">	sort.Sort(sliceutils.PodsByCreationTime(pods))</span><br><span class="line">	<span class="keyword">for</span> _, pod := <span class="keyword">range</span> pods &#123;</span><br><span class="line">		existingPods := kl.podManager.GetPods()</span><br><span class="line">		<span class="comment">// Always add the pod to the pod manager. Kubelet relies on the pod</span></span><br><span class="line">		<span class="comment">// manager as the source of truth for the desired state. If a pod does</span></span><br><span class="line">		<span class="comment">// not exist in the pod manager, it means that it has been deleted in</span></span><br><span class="line">		<span class="comment">// the apiserver and no action (other than cleanup) is required.</span></span><br><span class="line">		kl.podManager.AddPod(pod)</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> kubetypes.IsMirrorPod(pod) &#123;</span><br><span class="line">			kl.handleMirrorPod(pod, start)</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Only go through the admission process if the pod is not requested</span></span><br><span class="line">		<span class="comment">// for termination by another part of the kubelet. If the pod is already</span></span><br><span class="line">		<span class="comment">// using resources (previously admitted), the pod worker is going to be</span></span><br><span class="line">		<span class="comment">// shutting it down. If the pod hasn&#x27;t started yet, we know that when</span></span><br><span class="line">		<span class="comment">// the pod worker is invoked it will also avoid setting up the pod, so</span></span><br><span class="line">		<span class="comment">// we simply avoid doing any work.</span></span><br><span class="line">		<span class="keyword">if</span> !kl.podWorkers.IsPodTerminationRequested(pod.UID) &#123;</span><br><span class="line">			<span class="comment">// We failed pods that we rejected, so activePods include all admitted</span></span><br><span class="line">			<span class="comment">// pods that are alive.</span></span><br><span class="line">			activePods := kl.filterOutInactivePods(existingPods)</span><br><span class="line"></span><br><span class="line">			<span class="comment">// Check if we can admit the pod; if not, reject it.</span></span><br><span class="line">			<span class="keyword">if</span> ok, reason, message := kl.canAdmitPod(activePods, pod); !ok &#123;</span><br><span class="line">				kl.rejectPod(pod, reason, message)</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		mirrorPod, _ := kl.podManager.GetMirrorPodByPod(pod)</span><br><span class="line">		kl.dispatchWork(pod, kubetypes.SyncPodCreate, mirrorPod, start)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>新建Pod对应的ADD事件类型，直接由HandlePodAdditions处理。</p>
<p>HandlePodAdditions：通过dispatchWork-&gt;kl.podWorkers.UpdatePod的调用链，将Pod创建请求的发送给podWorkers做进一步的处理</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2238">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2238</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// HandlePodAdditions is the callback in SyncHandler for pods being added from</span></span><br><span class="line"><span class="comment">// a config source.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span></span> HandlePodAdditions(pods []*v1.Pod) &#123;</span><br><span class="line">	start := kl.clock.Now()</span><br><span class="line">	sort.Sort(sliceutils.PodsByCreationTime(pods))</span><br><span class="line">	<span class="keyword">for</span> _, pod := <span class="keyword">range</span> pods &#123;</span><br><span class="line">		existingPods := kl.podManager.GetPods()</span><br><span class="line">		<span class="comment">// Always add the pod to the pod manager. Kubelet relies on the pod</span></span><br><span class="line">		<span class="comment">// manager as the source of truth for the desired state. If a pod does</span></span><br><span class="line">		<span class="comment">// not exist in the pod manager, it means that it has been deleted in</span></span><br><span class="line">		<span class="comment">// the apiserver and no action (other than cleanup) is required.</span></span><br><span class="line">		kl.podManager.AddPod(pod)</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> kubetypes.IsMirrorPod(pod) &#123;</span><br><span class="line">			kl.handleMirrorPod(pod, start)</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Only go through the admission process if the pod is not requested</span></span><br><span class="line">		<span class="comment">// for termination by another part of the kubelet. If the pod is already</span></span><br><span class="line">		<span class="comment">// using resources (previously admitted), the pod worker is going to be</span></span><br><span class="line">		<span class="comment">// shutting it down. If the pod hasn&#x27;t started yet, we know that when</span></span><br><span class="line">		<span class="comment">// the pod worker is invoked it will also avoid setting up the pod, so</span></span><br><span class="line">		<span class="comment">// we simply avoid doing any work.</span></span><br><span class="line">		<span class="keyword">if</span> !kl.podWorkers.IsPodTerminationRequested(pod.UID) &#123;</span><br><span class="line">			<span class="comment">// We failed pods that we rejected, so activePods include all admitted</span></span><br><span class="line">			<span class="comment">// pods that are alive.</span></span><br><span class="line">			activePods := kl.filterOutInactivePods(existingPods)</span><br><span class="line"></span><br><span class="line">			<span class="comment">// Check if we can admit the pod; if not, reject it.</span></span><br><span class="line">			<span class="keyword">if</span> ok, reason, message := kl.canAdmitPod(activePods, pod); !ok &#123;</span><br><span class="line">				kl.rejectPod(pod, reason, message)</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		mirrorPod, _ := kl.podManager.GetMirrorPodByPod(pod)</span><br><span class="line">		kl.dispatchWork(pod, kubetypes.SyncPodCreate, mirrorPod, start)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>在处理新增Pod前，首先会进行排序操作，确保创建时间早的Pod总是能被优先处理。</p>
<ul>
<li>对于Static Pod的Mirror Pod，kubelet将忽略其Spec的变化，总是以File或HTTP源定义的PodSpec为准，更新Mirror POd。因此，用户无法通过删除或者修改Mirror pod的方式修改或者重启Staic Pod</li>
<li>kubelet在创建Mirror Pod时，会为其设置一个key为kubernetes.io&#x2F;config.mirror，value为static Pod的哈希值的Annotation，并且该值不能允许更新或者修改，在执行SyncPod，通过判断哈希值，判断是否需要重建Mirror Pod。</li>
</ul>
<p>在真正调用dispatch分发任务，还会通过canAdmitPod 执行节点级准入控制器</p>
<p>kubelte默认注册的准入控制器如下：</p>
<table>
<thead>
<tr>
<th align="center">准入控制器</th>
<th align="center">功能描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">EvictionAdmitHandler</td>
<td align="center">当面临资源压力的时候，拒绝可能影响节点稳定性的Pod运行，具体规则如下：1. Critical Pod不考虑资源压力，将被直接允许2. 对于仅仅存在内存压力的情况，Guranteed呵呵Burstable类型的Pod将被允许3.对于仅存在内存压力场景，当BestEffot类型的Pod容忍了内存压力污点时，将被允许4. 在其他情况下，Pod将会被拒绝访问</td>
</tr>
<tr>
<td align="center">SyctlsAllowlist</td>
<td align="center">检查Pod的SecurityContext定义中包含的sysctls是否在allowlist白名单中，默认许可的sysctls如下（可以通过–allow-unsafe-sysctls设置更多）1. “kernel.shm_rmid_forced” 2.  Net.ipv4.ip_local_port_ranage 3. Net.ipv4tcp_syncookies 4. Net.ipv4.ping_group_range 5.net.ipv4.ip_unprivileged_port_start</td>
</tr>
<tr>
<td align="center">AllocateResourcesPodAdmitHandler</td>
<td align="center">检查节点Device\CPU\Memory资源是否满足Pod需求。当启用TopologpyManager特性门控（默认开启），会合并资源拓扑分布是否满足Polcy策略</td>
</tr>
<tr>
<td align="center">PredicateAdmintHandler</td>
<td align="center">从调度特性评估Pod是否能够通过准入控制器，检查内容是否包括noderesources、nodeport、nodeAffity、nodeName、taint&#x2F;toleration。当Critical Pod被当前准入控制器拒绝且原因是资源不足时，将首先尝试驱逐低优先级Pod来释放需要的资源，以满足调度要求，此准入控制器次阿辉检查Pod的OS Label(kubernetes.io&#x2F;os)以及Field（Spec.OS.Name)是否和当前的kubelet运行OS匹配</td>
</tr>
<tr>
<td align="center">ShutdownAdmitHadnler</td>
<td align="center">在节点处于shutting关机中，拒绝所有Pod</td>
</tr>
</tbody></table>
<p>dispatchWork主要工作就是对Pod（创建、更新、删除、同步）事件下发给podWorkers做异步处理。</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2212">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L2212</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dispatchWork starts the asynchronous sync of the pod in a pod worker.</span></span><br><span class="line"><span class="comment">// If the pod has completed termination, dispatchWork will perform no action.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span></span> dispatchWork(pod *v1.Pod, syncType kubetypes.SyncPodType, mirrorPod *v1.Pod, start time.Time) &#123;</span><br><span class="line">	<span class="comment">// Run the sync in an async worker.</span></span><br><span class="line">	kl.podWorkers.UpdatePod(UpdatePodOptions&#123;</span><br><span class="line">		Pod:        pod,</span><br><span class="line">		MirrorPod:  mirrorPod,</span><br><span class="line">		UpdateType: syncType,</span><br><span class="line">		StartTime:  start,</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="comment">// Note the number of containers for new pods.</span></span><br><span class="line">	<span class="keyword">if</span> syncType == kubetypes.SyncPodCreate &#123;</span><br><span class="line">		metrics.ContainersPerPodCount.Observe(<span class="type">float64</span>(<span class="built_in">len</span>(pod.Spec.Containers)))</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="podWorkers收到Update事件，采用独立协程异步调用syncPod来处理"><a href="#podWorkers收到Update事件，采用独立协程异步调用syncPod来处理" class="headerlink" title="podWorkers收到Update事件，采用独立协程异步调用syncPod来处理"></a>podWorkers收到Update事件，采用独立协程异步调用syncPod来处理</h3><p>podWorkers会为每个Pod创建一个独立的任务Channel和一个goroutine，每个Pod处理协程都会阻塞式等待Channel中任务，并且对获取的任务进行处理。podWorkers则负责将Pod任务发送到对应的Channel中</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/pod_workers.go#L557">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/pod_workers.go#L557</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// UpdatePod carries a configuration change or termination state to a pod. A pod is either runnable,</span></span><br><span class="line"><span class="comment">// terminating, or terminated, and will transition to terminating if deleted on the apiserver, it is</span></span><br><span class="line"><span class="comment">// discovered to have a terminal phase (Succeeded or Failed), or if it is evicted by the kubelet.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *podWorkers)</span></span> UpdatePod(options UpdatePodOptions) &#123;</span><br><span class="line">	<span class="comment">// handle when the pod is an orphan (no config) and we only have runtime status by running only</span></span><br><span class="line">	<span class="comment">// the terminating part of the lifecycle</span></span><br><span class="line">	pod := options.Pod</span><br><span class="line">	<span class="keyword">var</span> isRuntimePod <span class="type">bool</span></span><br><span class="line">	<span class="keyword">if</span> options.RunningPod != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> options.Pod == <span class="literal">nil</span> &#123;</span><br><span class="line">			pod = options.RunningPod.ToAPIPod()</span><br><span class="line">			<span class="keyword">if</span> options.UpdateType != kubetypes.SyncPodKill &#123;</span><br><span class="line">				klog.InfoS(<span class="string">&quot;Pod update is ignored, runtime pods can only be killed&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">				<span class="keyword">return</span></span><br><span class="line">			&#125;</span><br><span class="line">			options.Pod = pod</span><br><span class="line">			isRuntimePod = <span class="literal">true</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			options.RunningPod = <span class="literal">nil</span></span><br><span class="line">			klog.InfoS(<span class="string">&quot;Pod update included RunningPod which is only valid when Pod is not specified&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(options.Pod), <span class="string">&quot;podUID&quot;</span>, options.Pod.UID)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	uid := pod.UID</span><br><span class="line"></span><br><span class="line">	p.podLock.Lock()</span><br><span class="line">	<span class="keyword">defer</span> p.podLock.Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// decide what to do with this pod - we are either setting it up, tearing it down, or ignoring it</span></span><br><span class="line">	now := time.Now()</span><br><span class="line">	status, ok := p.podSyncStatuses[uid]</span><br><span class="line">	<span class="keyword">if</span> !ok &#123;</span><br><span class="line">		klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is being synced for the first time&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">		status = &amp;podSyncStatus&#123;</span><br><span class="line">			syncedAt: now,</span><br><span class="line">			fullname: kubecontainer.GetPodFullName(pod),</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// if this pod is being synced for the first time, we need to make sure it is an active pod</span></span><br><span class="line">		<span class="keyword">if</span> !isRuntimePod &amp;&amp; (pod.Status.Phase == v1.PodFailed || pod.Status.Phase == v1.PodSucceeded) &#123;</span><br><span class="line">			<span class="comment">// check to see if the pod is not running and the pod is terminal.</span></span><br><span class="line">			<span class="comment">// If this succeeds then record in the podWorker that it is terminated.</span></span><br><span class="line">			<span class="keyword">if</span> statusCache, err := p.podCache.Get(pod.UID); err == <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="keyword">if</span> isPodStatusCacheTerminal(statusCache) &#123;</span><br><span class="line">					status = &amp;podSyncStatus&#123;</span><br><span class="line">						terminatedAt:       now,</span><br><span class="line">						terminatingAt:      now,</span><br><span class="line">						syncedAt:           now,</span><br><span class="line">						startedTerminating: <span class="literal">true</span>,</span><br><span class="line">						finished:           <span class="literal">true</span>,</span><br><span class="line">						fullname:           kubecontainer.GetPodFullName(pod),</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		p.podSyncStatuses[uid] = status</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// if an update is received that implies the pod should be running, but we are already terminating a pod by</span></span><br><span class="line">	<span class="comment">// that UID, assume that two pods with the same UID were created in close temporal proximity (usually static</span></span><br><span class="line">	<span class="comment">// pod but it&#x27;s possible for an apiserver to extremely rarely do something similar) - flag the sync status</span></span><br><span class="line">	<span class="comment">// to indicate that after the pod terminates it should be reset to &quot;not running&quot; to allow a subsequent add/update</span></span><br><span class="line">	<span class="comment">// to start the pod worker again</span></span><br><span class="line">	<span class="keyword">if</span> status.IsTerminationRequested() &#123;</span><br><span class="line">		<span class="keyword">if</span> options.UpdateType == kubetypes.SyncPodCreate &#123;</span><br><span class="line">			status.restartRequested = <span class="literal">true</span></span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is terminating but has been requested to restart with same UID, will be reconciled later&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// once a pod is terminated by UID, it cannot reenter the pod worker (until the UID is purged by housekeeping)</span></span><br><span class="line">	<span class="keyword">if</span> status.IsFinished() &#123;</span><br><span class="line">		klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is finished processing, no further updates&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// check for a transition to terminating</span></span><br><span class="line">	<span class="keyword">var</span> becameTerminating <span class="type">bool</span></span><br><span class="line">	<span class="keyword">if</span> !status.IsTerminationRequested() &#123;</span><br><span class="line">		<span class="keyword">switch</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> isRuntimePod:</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is orphaned and must be torn down&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">			status.deleted = <span class="literal">true</span></span><br><span class="line">			status.terminatingAt = now</span><br><span class="line">			becameTerminating = <span class="literal">true</span></span><br><span class="line">		<span class="keyword">case</span> pod.DeletionTimestamp != <span class="literal">nil</span>:</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is marked for graceful deletion, begin teardown&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">			status.deleted = <span class="literal">true</span></span><br><span class="line">			status.terminatingAt = now</span><br><span class="line">			becameTerminating = <span class="literal">true</span></span><br><span class="line">		<span class="keyword">case</span> pod.Status.Phase == v1.PodFailed, pod.Status.Phase == v1.PodSucceeded:</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is in a terminal phase (success/failed), begin teardown&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">			status.terminatingAt = now</span><br><span class="line">			becameTerminating = <span class="literal">true</span></span><br><span class="line">		<span class="keyword">case</span> options.UpdateType == kubetypes.SyncPodKill:</span><br><span class="line">			<span class="keyword">if</span> options.KillPodOptions != <span class="literal">nil</span> &amp;&amp; options.KillPodOptions.Evict &#123;</span><br><span class="line">				klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is being evicted by the kubelet, begin teardown&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">				status.evicted = <span class="literal">true</span></span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Pod is being removed by the kubelet, begin teardown&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">			&#125;</span><br><span class="line">			status.terminatingAt = now</span><br><span class="line">			becameTerminating = <span class="literal">true</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// once a pod is terminating, all updates are kills and the grace period can only decrease</span></span><br><span class="line">	<span class="keyword">var</span> workType PodWorkType</span><br><span class="line">	<span class="keyword">var</span> wasGracePeriodShortened <span class="type">bool</span></span><br><span class="line">	<span class="keyword">switch</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> status.IsTerminated():</span><br><span class="line">		<span class="comment">// A terminated pod may still be waiting for cleanup - if we receive a runtime pod kill request</span></span><br><span class="line">		<span class="comment">// due to housekeeping seeing an older cached version of the runtime pod simply ignore it until</span></span><br><span class="line">		<span class="comment">// after the pod worker completes.</span></span><br><span class="line">		<span class="keyword">if</span> isRuntimePod &#123;</span><br><span class="line">			klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;Pod is waiting for termination, ignoring runtime-only kill until after pod worker is fully terminated&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		workType = TerminatedPodWork</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> options.KillPodOptions != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> ch := options.KillPodOptions.CompletedCh; ch != <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="built_in">close</span>(ch)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		options.KillPodOptions = <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">case</span> status.IsTerminationRequested():</span><br><span class="line">		workType = TerminatingPodWork</span><br><span class="line">		<span class="keyword">if</span> options.KillPodOptions == <span class="literal">nil</span> &#123;</span><br><span class="line">			options.KillPodOptions = &amp;KillPodOptions&#123;&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> ch := options.KillPodOptions.CompletedCh; ch != <span class="literal">nil</span> &#123;</span><br><span class="line">			status.notifyPostTerminating = <span class="built_in">append</span>(status.notifyPostTerminating, ch)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> fn := options.KillPodOptions.PodStatusFunc; fn != <span class="literal">nil</span> &#123;</span><br><span class="line">			status.statusPostTerminating = <span class="built_in">append</span>(status.statusPostTerminating, fn)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		gracePeriod, gracePeriodShortened := calculateEffectiveGracePeriod(status, pod, options.KillPodOptions)</span><br><span class="line"></span><br><span class="line">		wasGracePeriodShortened = gracePeriodShortened</span><br><span class="line">		status.gracePeriod = gracePeriod</span><br><span class="line">		<span class="comment">// always set the grace period for syncTerminatingPod so we don&#x27;t have to recalculate,</span></span><br><span class="line">		<span class="comment">// will never be zero.</span></span><br><span class="line">		options.KillPodOptions.PodTerminationGracePeriodSecondsOverride = &amp;gracePeriod</span><br><span class="line"></span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		workType = SyncPodWork</span><br><span class="line"></span><br><span class="line">		<span class="comment">// KillPodOptions is not valid for sync actions outside of the terminating phase</span></span><br><span class="line">		<span class="keyword">if</span> options.KillPodOptions != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> ch := options.KillPodOptions.CompletedCh; ch != <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="built_in">close</span>(ch)</span><br><span class="line">			&#125;</span><br><span class="line">			options.KillPodOptions = <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// the desired work we want to be performing</span></span><br><span class="line">	work := podWork&#123;</span><br><span class="line">		WorkType: workType,</span><br><span class="line">		Options:  options,</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// start the pod worker goroutine if it doesn&#x27;t exist</span></span><br><span class="line">	podUpdates, exists := p.podUpdates[uid]</span><br><span class="line">	<span class="keyword">if</span> !exists &#123;</span><br><span class="line">		<span class="comment">// We need to have a buffer here, because checkForUpdates() method that</span></span><br><span class="line">		<span class="comment">// puts an update into channel is called from the same goroutine where</span></span><br><span class="line">		<span class="comment">// the channel is consumed. However, it is guaranteed that in such case</span></span><br><span class="line">		<span class="comment">// the channel is empty, so buffer of size 1 is enough.</span></span><br><span class="line">		podUpdates = <span class="built_in">make</span>(<span class="keyword">chan</span> podWork, <span class="number">1</span>)</span><br><span class="line">		p.podUpdates[uid] = podUpdates</span><br><span class="line"></span><br><span class="line">		<span class="comment">// ensure that static pods start in the order they are received by UpdatePod</span></span><br><span class="line">		<span class="keyword">if</span> kubetypes.IsStaticPod(pod) &#123;</span><br><span class="line">			p.waitingToStartStaticPodsByFullname[status.fullname] =</span><br><span class="line">				<span class="built_in">append</span>(p.waitingToStartStaticPodsByFullname[status.fullname], uid)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// allow testing of delays in the pod update channel</span></span><br><span class="line">		<span class="keyword">var</span> outCh &lt;-<span class="keyword">chan</span> podWork</span><br><span class="line">		<span class="keyword">if</span> p.workerChannelFn != <span class="literal">nil</span> &#123;</span><br><span class="line">			outCh = p.workerChannelFn(uid, podUpdates)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			outCh = podUpdates</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Creating a new pod worker either means this is a new pod, or that the</span></span><br><span class="line">		<span class="comment">// kubelet just restarted. In either case the kubelet is willing to believe</span></span><br><span class="line">		<span class="comment">// the status of the pod for the first pod worker sync. See corresponding</span></span><br><span class="line">		<span class="comment">// comment in syncPod.</span></span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="keyword">defer</span> runtime.HandleCrash()</span><br><span class="line">			p.managePodLoop(outCh)</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// dispatch a request to the pod worker if none are running</span></span><br><span class="line">	<span class="keyword">if</span> !status.IsWorking() &#123;</span><br><span class="line">		status.working = <span class="literal">true</span></span><br><span class="line">		podUpdates &lt;- work</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// capture the maximum latency between a requested update and when the pod</span></span><br><span class="line">	<span class="comment">// worker observes it</span></span><br><span class="line">	<span class="keyword">if</span> undelivered, ok := p.lastUndeliveredWorkUpdate[pod.UID]; ok &#123;</span><br><span class="line">		<span class="comment">// track the max latency between when a config change is requested and when it is realized</span></span><br><span class="line">		<span class="comment">// <span class="doctag">NOTE:</span> this undercounts the latency when multiple requests are queued, but captures max latency</span></span><br><span class="line">		<span class="keyword">if</span> !undelivered.Options.StartTime.IsZero() &amp;&amp; undelivered.Options.StartTime.Before(work.Options.StartTime) &#123;</span><br><span class="line">			work.Options.StartTime = undelivered.Options.StartTime</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// always sync the most recent data</span></span><br><span class="line">	p.lastUndeliveredWorkUpdate[pod.UID] = work</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (becameTerminating || wasGracePeriodShortened) &amp;&amp; status.cancelFn != <span class="literal">nil</span> &#123;</span><br><span class="line">		klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;Cancelling current pod sync&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID, <span class="string">&quot;updateType&quot;</span>, work.WorkType)</span><br><span class="line">		status.cancelFn()</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>UpdatePod首先构造出work任务对象，WorkType支持三种类型，即SyncPodWork、TerminatingPodWork和TerminatePodWork分别对应kl.syncPod\kl.syncTerminatingPod\kl.syncTerminatedPod</li>
<li>根据Pod UID检索是否已经支持对应的work Channel，如果没有则为Pod创建一个Channel和goroutine</li>
<li>将work任务发送给Pod的任务的Channel</li>
</ol>
</li>
</ul>
<h3 id="执行容器创建准备工作-包括检查网络、设置cgroup、挂载磁盘等"><a href="#执行容器创建准备工作-包括检查网络、设置cgroup、挂载磁盘等" class="headerlink" title="执行容器创建准备工作(包括检查网络、设置cgroup、挂载磁盘等)"></a>执行容器创建准备工作(包括检查网络、设置cgroup、挂载磁盘等)</h3><p>podWorkers的syncPodFn实际上就是kl.ysncPod</p>
<ul>
<li><p>Ref：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L1522">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kubelet.go#L1522</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span></span> syncPod(ctx context.Context, updateType kubetypes.SyncPodType, pod, mirrorPod *v1.Pod, podStatus *kubecontainer.PodStatus) (isTerminal <span class="type">bool</span>, err <span class="type">error</span>) &#123;</span><br><span class="line">	klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;syncPod enter&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID)</span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;syncPod exit&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID, <span class="string">&quot;isTerminal&quot;</span>, isTerminal)</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Latency measurements for the main workflow are relative to the</span></span><br><span class="line">	<span class="comment">// first time the pod was seen by kubelet.</span></span><br><span class="line">	<span class="keyword">var</span> firstSeenTime time.Time</span><br><span class="line">	<span class="keyword">if</span> firstSeenTimeStr, ok := pod.Annotations[kubetypes.ConfigFirstSeenAnnotationKey]; ok &#123;</span><br><span class="line">		firstSeenTime = kubetypes.ConvertToTimestamp(firstSeenTimeStr).Get()</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Record pod worker start latency if being created</span></span><br><span class="line">	<span class="comment">// <span class="doctag">TODO:</span> make pod workers record their own latencies</span></span><br><span class="line">	<span class="keyword">if</span> updateType == kubetypes.SyncPodCreate &#123;</span><br><span class="line">		<span class="keyword">if</span> !firstSeenTime.IsZero() &#123;</span><br><span class="line">			<span class="comment">// This is the first time we are syncing the pod. Record the latency</span></span><br><span class="line">			<span class="comment">// since kubelet first saw the pod if firstSeenTime is set.</span></span><br><span class="line">			metrics.PodWorkerStartDuration.Observe(metrics.SinceInSeconds(firstSeenTime))</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;First seen time not recorded for pod&quot;</span>,</span><br><span class="line">				<span class="string">&quot;podUID&quot;</span>, pod.UID,</span><br><span class="line">				<span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Generate final API pod status with pod and status manager status</span></span><br><span class="line">	apiPodStatus := kl.generateAPIPodStatus(pod, podStatus)</span><br><span class="line">	<span class="comment">// The pod IP may be changed in generateAPIPodStatus if the pod is using host network. (See #24576)</span></span><br><span class="line">	<span class="comment">// TODO(random-liu): After writing pod spec into container labels, check whether pod is using host network, and</span></span><br><span class="line">	<span class="comment">// set pod IP to hostIP directly in runtime.GetPodStatus</span></span><br><span class="line">	podStatus.IPs = <span class="built_in">make</span>([]<span class="type">string</span>, <span class="number">0</span>, <span class="built_in">len</span>(apiPodStatus.PodIPs))</span><br><span class="line">	<span class="keyword">for</span> _, ipInfo := <span class="keyword">range</span> apiPodStatus.PodIPs &#123;</span><br><span class="line">		podStatus.IPs = <span class="built_in">append</span>(podStatus.IPs, ipInfo.IP)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(podStatus.IPs) == <span class="number">0</span> &amp;&amp; <span class="built_in">len</span>(apiPodStatus.PodIP) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		podStatus.IPs = []<span class="type">string</span>&#123;apiPodStatus.PodIP&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// If the pod is terminal, we don&#x27;t need to continue to setup the pod</span></span><br><span class="line">	<span class="keyword">if</span> apiPodStatus.Phase == v1.PodSucceeded || apiPodStatus.Phase == v1.PodFailed &#123;</span><br><span class="line">		kl.statusManager.SetPodStatus(pod, apiPodStatus)</span><br><span class="line">		isTerminal = <span class="literal">true</span></span><br><span class="line">		<span class="keyword">return</span> isTerminal, <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// If the pod should not be running, we request the pod&#x27;s containers be stopped. This is not the same</span></span><br><span class="line">	<span class="comment">// as termination (we want to stop the pod, but potentially restart it later if soft admission allows</span></span><br><span class="line">	<span class="comment">// it later). Set the status and phase appropriately</span></span><br><span class="line">	runnable := kl.canRunPod(pod)</span><br><span class="line">	<span class="keyword">if</span> !runnable.Admit &#123;</span><br><span class="line">		<span class="comment">// Pod is not runnable; and update the Pod and Container statuses to why.</span></span><br><span class="line">		<span class="keyword">if</span> apiPodStatus.Phase != v1.PodFailed &amp;&amp; apiPodStatus.Phase != v1.PodSucceeded &#123;</span><br><span class="line">			apiPodStatus.Phase = v1.PodPending</span><br><span class="line">		&#125;</span><br><span class="line">		apiPodStatus.Reason = runnable.Reason</span><br><span class="line">		apiPodStatus.Message = runnable.Message</span><br><span class="line">		<span class="comment">// Waiting containers are not creating.</span></span><br><span class="line">		<span class="keyword">const</span> waitingReason = <span class="string">&quot;Blocked&quot;</span></span><br><span class="line">		<span class="keyword">for</span> _, cs := <span class="keyword">range</span> apiPodStatus.InitContainerStatuses &#123;</span><br><span class="line">			<span class="keyword">if</span> cs.State.Waiting != <span class="literal">nil</span> &#123;</span><br><span class="line">				cs.State.Waiting.Reason = waitingReason</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">for</span> _, cs := <span class="keyword">range</span> apiPodStatus.ContainerStatuses &#123;</span><br><span class="line">			<span class="keyword">if</span> cs.State.Waiting != <span class="literal">nil</span> &#123;</span><br><span class="line">				cs.State.Waiting.Reason = waitingReason</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Record the time it takes for the pod to become running</span></span><br><span class="line">	<span class="comment">// since kubelet first saw the pod if firstSeenTime is set.</span></span><br><span class="line">	existingStatus, ok := kl.statusManager.GetPodStatus(pod.UID)</span><br><span class="line">	<span class="keyword">if</span> !ok || existingStatus.Phase == v1.PodPending &amp;&amp; apiPodStatus.Phase == v1.PodRunning &amp;&amp;</span><br><span class="line">		!firstSeenTime.IsZero() &#123;</span><br><span class="line">		metrics.PodStartDuration.Observe(metrics.SinceInSeconds(firstSeenTime))</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	kl.statusManager.SetPodStatus(pod, apiPodStatus)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Pods that are not runnable must be stopped - return a typed error to the pod worker</span></span><br><span class="line">	<span class="keyword">if</span> !runnable.Admit &#123;</span><br><span class="line">		klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;Pod is not runnable and must have running containers stopped&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, pod.UID, <span class="string">&quot;message&quot;</span>, runnable.Message)</span><br><span class="line">		<span class="keyword">var</span> syncErr <span class="type">error</span></span><br><span class="line">		p := kubecontainer.ConvertPodStatusToRunningPod(kl.getRuntime().Type(), podStatus)</span><br><span class="line">		<span class="keyword">if</span> err := kl.killPod(pod, p, <span class="literal">nil</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToKillPod, <span class="string">&quot;error killing pod: %v&quot;</span>, err)</span><br><span class="line">			syncErr = fmt.Errorf(<span class="string">&quot;error killing pod: %v&quot;</span>, err)</span><br><span class="line">			utilruntime.HandleError(syncErr)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">// There was no error killing the pod, but the pod cannot be run.</span></span><br><span class="line">			<span class="comment">// Return an error to signal that the sync loop should back off.</span></span><br><span class="line">			syncErr = fmt.Errorf(<span class="string">&quot;pod cannot be run: %s&quot;</span>, runnable.Message)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>, syncErr</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// If the network plugin is not ready, only start the pod if it uses the host network</span></span><br><span class="line">	<span class="keyword">if</span> err := kl.runtimeState.networkErrors(); err != <span class="literal">nil</span> &amp;&amp; !kubecontainer.IsHostNetworkPod(pod) &#123;</span><br><span class="line">		kl.recorder.Eventf(pod, v1.EventTypeWarning, events.NetworkNotReady, <span class="string">&quot;%s: %v&quot;</span>, NetworkNotReadyErrorMsg, err)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>, fmt.Errorf(<span class="string">&quot;%s: %v&quot;</span>, NetworkNotReadyErrorMsg, err)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// ensure the kubelet knows about referenced secrets or configmaps used by the pod</span></span><br><span class="line">	<span class="keyword">if</span> !kl.podWorkers.IsPodTerminationRequested(pod.UID) &#123;</span><br><span class="line">		<span class="keyword">if</span> kl.secretManager != <span class="literal">nil</span> &#123;</span><br><span class="line">			kl.secretManager.RegisterPod(pod)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> kl.configMapManager != <span class="literal">nil</span> &#123;</span><br><span class="line">			kl.configMapManager.RegisterPod(pod)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Create Cgroups for the pod and apply resource parameters</span></span><br><span class="line">	<span class="comment">// to them if cgroups-per-qos flag is enabled.</span></span><br><span class="line">	pcm := kl.containerManager.NewPodContainerManager()</span><br><span class="line">	<span class="comment">// If pod has already been terminated then we need not create</span></span><br><span class="line">	<span class="comment">// or update the pod&#x27;s cgroup</span></span><br><span class="line">	<span class="comment">// <span class="doctag">TODO:</span> once context cancellation is added this check can be removed</span></span><br><span class="line">	<span class="keyword">if</span> !kl.podWorkers.IsPodTerminationRequested(pod.UID) &#123;</span><br><span class="line">		<span class="comment">// When the kubelet is restarted with the cgroups-per-qos</span></span><br><span class="line">		<span class="comment">// flag enabled, all the pod&#x27;s running containers</span></span><br><span class="line">		<span class="comment">// should be killed intermittently and brought back up</span></span><br><span class="line">		<span class="comment">// under the qos cgroup hierarchy.</span></span><br><span class="line">		<span class="comment">// Check if this is the pod&#x27;s first sync</span></span><br><span class="line">		firstSync := <span class="literal">true</span></span><br><span class="line">		<span class="keyword">for</span> _, containerStatus := <span class="keyword">range</span> apiPodStatus.ContainerStatuses &#123;</span><br><span class="line">			<span class="keyword">if</span> containerStatus.State.Running != <span class="literal">nil</span> &#123;</span><br><span class="line">				firstSync = <span class="literal">false</span></span><br><span class="line">				<span class="keyword">break</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// Don&#x27;t kill containers in pod if pod&#x27;s cgroups already</span></span><br><span class="line">		<span class="comment">// exists or the pod is running for the first time</span></span><br><span class="line">		podKilled := <span class="literal">false</span></span><br><span class="line">		<span class="keyword">if</span> !pcm.Exists(pod) &amp;&amp; !firstSync &#123;</span><br><span class="line">			p := kubecontainer.ConvertPodStatusToRunningPod(kl.getRuntime().Type(), podStatus)</span><br><span class="line">			<span class="keyword">if</span> err := kl.killPod(pod, p, <span class="literal">nil</span>); err == <span class="literal">nil</span> &#123;</span><br><span class="line">				podKilled = <span class="literal">true</span></span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				klog.ErrorS(err, <span class="string">&quot;KillPod failed&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podStatus&quot;</span>, podStatus)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// Create and Update pod&#x27;s Cgroups</span></span><br><span class="line">		<span class="comment">// Don&#x27;t create cgroups for run once pod if it was killed above</span></span><br><span class="line">		<span class="comment">// The current policy is not to restart the run once pods when</span></span><br><span class="line">		<span class="comment">// the kubelet is restarted with the new flag as run once pods are</span></span><br><span class="line">		<span class="comment">// expected to run only once and if the kubelet is restarted then</span></span><br><span class="line">		<span class="comment">// they are not expected to run again.</span></span><br><span class="line">		<span class="comment">// We don&#x27;t create and apply updates to cgroup if its a run once pod and was killed above</span></span><br><span class="line">		<span class="keyword">if</span> !(podKilled &amp;&amp; pod.Spec.RestartPolicy == v1.RestartPolicyNever) &#123;</span><br><span class="line">			<span class="keyword">if</span> !pcm.Exists(pod) &#123;</span><br><span class="line">				<span class="keyword">if</span> err := kl.containerManager.UpdateQOSCgroups(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">					klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;Failed to update QoS cgroups while syncing pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;err&quot;</span>, err)</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">if</span> err := pcm.EnsureExists(pod); err != <span class="literal">nil</span> &#123;</span><br><span class="line">					kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToCreatePodContainer, <span class="string">&quot;unable to ensure pod container exists: %v&quot;</span>, err)</span><br><span class="line">					<span class="keyword">return</span> <span class="literal">false</span>, fmt.Errorf(<span class="string">&quot;failed to ensure that the pod: %v cgroups exist and are correctly applied: %v&quot;</span>, pod.UID, err)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Create Mirror Pod for Static Pod if it doesn&#x27;t already exist</span></span><br><span class="line">	<span class="keyword">if</span> kubetypes.IsStaticPod(pod) &#123;</span><br><span class="line">		deleted := <span class="literal">false</span></span><br><span class="line">		<span class="keyword">if</span> mirrorPod != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> mirrorPod.DeletionTimestamp != <span class="literal">nil</span> || !kl.podManager.IsMirrorPodOf(mirrorPod, pod) &#123;</span><br><span class="line">				<span class="comment">// The mirror pod is semantically different from the static pod. Remove</span></span><br><span class="line">				<span class="comment">// it. The mirror pod will get recreated later.</span></span><br><span class="line">				klog.InfoS(<span class="string">&quot;Trying to delete pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;podUID&quot;</span>, mirrorPod.ObjectMeta.UID)</span><br><span class="line">				podFullName := kubecontainer.GetPodFullName(pod)</span><br><span class="line">				<span class="keyword">var</span> err <span class="type">error</span></span><br><span class="line">				deleted, err = kl.podManager.DeleteMirrorPod(podFullName, &amp;mirrorPod.ObjectMeta.UID)</span><br><span class="line">				<span class="keyword">if</span> deleted &#123;</span><br><span class="line">					klog.InfoS(<span class="string">&quot;Deleted mirror pod because it is outdated&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(mirrorPod))</span><br><span class="line">				&#125; <span class="keyword">else</span> <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">					klog.ErrorS(err, <span class="string">&quot;Failed deleting mirror pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(mirrorPod))</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> mirrorPod == <span class="literal">nil</span> || deleted &#123;</span><br><span class="line">			node, err := kl.GetNode()</span><br><span class="line">			<span class="keyword">if</span> err != <span class="literal">nil</span> || node.DeletionTimestamp != <span class="literal">nil</span> &#123;</span><br><span class="line">				klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;No need to create a mirror pod, since node has been removed from the cluster&quot;</span>, <span class="string">&quot;node&quot;</span>, klog.KRef(<span class="string">&quot;&quot;</span>, <span class="type">string</span>(kl.nodeName)))</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;Creating a mirror pod for static pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">				<span class="keyword">if</span> err := kl.podManager.CreateMirrorPod(pod); err != <span class="literal">nil</span> &#123;</span><br><span class="line">					klog.ErrorS(err, <span class="string">&quot;Failed creating a mirror pod for&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Make data directories for the pod</span></span><br><span class="line">	<span class="keyword">if</span> err := kl.makePodDataDirs(pod); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToMakePodDataDirectories, <span class="string">&quot;error making pod data directories: %v&quot;</span>, err)</span><br><span class="line">		klog.ErrorS(err, <span class="string">&quot;Unable to make pod data directories for pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Volume manager will not mount volumes for terminating pods</span></span><br><span class="line">	<span class="comment">// <span class="doctag">TODO:</span> once context cancellation is added this check can be removed</span></span><br><span class="line">	<span class="keyword">if</span> !kl.podWorkers.IsPodTerminationRequested(pod.UID) &#123;</span><br><span class="line">		<span class="comment">// Wait for volumes to attach/mount</span></span><br><span class="line">		<span class="keyword">if</span> err := kl.volumeManager.WaitForAttachAndMount(pod); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedMountVolume, <span class="string">&quot;Unable to attach or mount volumes: %v&quot;</span>, err)</span><br><span class="line">			klog.ErrorS(err, <span class="string">&quot;Unable to attach or mount volumes for pod; skipping pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">false</span>, err</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Fetch the pull secrets for the pod</span></span><br><span class="line">	pullSecrets := kl.getPullSecretsForPod(pod)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Ensure the pod is being probed</span></span><br><span class="line">	kl.probeManager.AddPod(pod)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Call the container runtime&#x27;s SyncPod callback</span></span><br><span class="line">	result := kl.containerRuntime.SyncPod(pod, podStatus, pullSecrets, kl.backOff)</span><br><span class="line">	kl.reasonCache.Update(pod.UID, result)</span><br><span class="line">	<span class="keyword">if</span> err := result.Error(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="comment">// Do not return error if the only failures were pods in backoff</span></span><br><span class="line">		<span class="keyword">for</span> _, r := <span class="keyword">range</span> result.SyncResults &#123;</span><br><span class="line">			<span class="keyword">if</span> r.Error != kubecontainer.ErrCrashLoopBackOff &amp;&amp; r.Error != images.ErrImagePullBackOff &#123;</span><br><span class="line">				<span class="comment">// Do not record an event here, as we keep all event logging for sync pod failures</span></span><br><span class="line">				<span class="comment">// local to container runtime, so we get better errors.</span></span><br><span class="line">				<span class="keyword">return</span> <span class="literal">false</span>, err</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>, <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>syncPod 主要步骤如下：</p>
<ol>
<li><p>通过canRunPod检查是否能够在当前节点启动。canRunPod内部遍历softAdmitHandlers准入控制器列表，分别调用各准入控制器Admit func。</p>
<ul>
<li>如果有任意一个准入控制器返回拒绝，则拒绝运行Pod</li>
</ul>
</li>
<li><p>通过runtimeState.networkErrors检查网络插件是否就绪</p>
<ul>
<li>如果网络插件未就绪，值启动Host Network类型的Pod。网络插件状态由容器运行时检测并且反馈，kubelet通过CRI的Status接口的StatusResponse响应，通过判断RuntimeStatus中的Conditions是否包含NetworkReady来确定网络插件是否就绪</li>
</ul>
</li>
<li><p>通过secretManager.RegisterPod\configMapManager.ResgisterPod将当前Pod注册到相应的manager，以将Pod引用的Secret和ConfigMap对象注册到Manager，通过watch、TTL等机制维护kubelet本地缓存，方便在Pod挂载时快速读取，避免每次同步Pod都向kube-apiserver发起请求</p>
</li>
<li><p>当<code>--cgroups-per-qos</code>参数被启用（默认被启用），通过pcm.EnsureExists为Pod设置Pod级别的cgroup资源限制，而QoS级别的cgroup层级通过containerManager.UpdateQOSCgroups处理。QOSContainerManager通过内部协程每隔1min执行一次UpdateCgroups同步操作</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/cm/pod_container_manager_linux.go#L72">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/cm/pod_container_manager_linux.go#L72</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// EnsureExists takes a pod as argument and makes sure that</span></span><br><span class="line"><span class="comment">// pod cgroup exists if qos cgroup hierarchy flag is enabled.</span></span><br><span class="line"><span class="comment">// If the pod level container doesn&#x27;t already exist it is created.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *podContainerManagerImpl)</span></span> EnsureExists(pod *v1.Pod) <span class="type">error</span> &#123;</span><br><span class="line">	podContainerName, _ := m.GetPodContainerName(pod)</span><br><span class="line">	<span class="comment">// check if container already exist</span></span><br><span class="line">	alreadyExists := m.Exists(pod)</span><br><span class="line">	<span class="keyword">if</span> !alreadyExists &#123;</span><br><span class="line">		enforceMemoryQoS := <span class="literal">false</span></span><br><span class="line">		<span class="keyword">if</span> utilfeature.DefaultFeatureGate.Enabled(kubefeatures.MemoryQoS) &amp;&amp;</span><br><span class="line">			libcontainercgroups.IsCgroup2UnifiedMode() &#123;</span><br><span class="line">			enforceMemoryQoS = <span class="literal">true</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// Create the pod container</span></span><br><span class="line">		containerConfig := &amp;CgroupConfig&#123;</span><br><span class="line">			Name:               podContainerName,</span><br><span class="line">			ResourceParameters: ResourceConfigForPod(pod, m.enforceCPULimits, m.cpuCFSQuotaPeriod, enforceMemoryQoS),</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> m.podPidsLimit &gt; <span class="number">0</span> &#123;</span><br><span class="line">			containerConfig.ResourceParameters.PidsLimit = &amp;m.podPidsLimit</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> enforceMemoryQoS &#123;</span><br><span class="line">			klog.V(<span class="number">4</span>).InfoS(<span class="string">&quot;MemoryQoS config for pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;unified&quot;</span>, containerConfig.ResourceParameters.Unified)</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> err := m.cgroupManager.Create(containerConfig); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> fmt.Errorf(<span class="string">&quot;failed to create container for %v : %v&quot;</span>, podContainerName, err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<p>  <img src="https://raw.githubusercontent.com/Piwriw/PicGo/master/image202412162215167.png"></p>
<ul>
<li>这里没有Memory Requests，是否设置Memory Request并不重要吗？不是，requests更多调度阶段才被关注，limits在运行阶段更多被关注</li>
</ul>
<blockquote>
<p>kubelet通过EnsureExists实现了Pod级别的cgroup资源限制，更低层级的Container级别的cgroup资源借助CRI来完成</p>
</blockquote>
<p>通过makePodDataDirs 为Pod准备以下文件夹：</p>
<ul>
<li><code>/var/lib/kubelet/pods/&lt;pod_uid&gt;</code></li>
<li><code>/var/lib/kubelet/pods/&lt;pod_uid&gt;/volumes</code></li>
<li><code>/var/lib/kubelet/pods/&lt;pod_uid&gt;/plugins</code></li>
</ul>
<p>对于使用了存储卷的Pod，通过volumeManager.WaitForAttachAndMount等待VolumeManager完成对存储卷Attach和Mount操作，挂载后的数据卷会在宿主机的&#x2F;var&#x2F;lib&#x2F;kubelete&#x2F;pods&#x2F;<pod_uid>&#x2F;<volumes>文件夹下体现，在创建容器时通过容器运行时挂载到容器中</p>
<ul>
<li>启动条件就绪，通过probeManager.AddPod将Pod加入到健康检查探测，再通过SyncPod创建容器</li>
</ul>
<h3 id="调用CRI创建Sandbox隔离环境（包含调用CNI设置网络）"><a href="#调用CRI创建Sandbox隔离环境（包含调用CNI设置网络）" class="headerlink" title="调用CRI创建Sandbox隔离环境（包含调用CNI设置网络）"></a>调用CRI创建Sandbox隔离环境（包含调用CNI设置网络）</h3><p>containerRuntimes.SyncPod执行主要是以下几步：</p>
<ol>
<li>计算Sandbox隔离环境是否发生了变化，如Pod的网络从容器网络切换为主机网络会导致Sandbox隔离环境改变</li>
<li>如果Sandbox隔离环境发生了变化，则重建Sandbox隔离环境</li>
<li>根据计算结果，终止不应该保持继续运行的容器</li>
<li>如果需要，为Pod创建新的Sandbox隔离环境</li>
<li>创建临时容器</li>
<li>创建初始化容器</li>
<li>创建普通业务容器</li>
</ol>
<p>对于Pod启动而言，较为核心的就是创建Sandbox隔离环境和运行普通容器环境。</p>
<ol>
<li><p>首先，通过generatePodSandboxConfig生成runtimeapi.PodSandboxConfig对象，内部包含创建Sandbox隔离环境所需要的信息，如基本元信息</p>
</li>
<li><p>为Pod生存日志目录，默认为<code>/var/log/pods/&lt;pod_uid&gt;</code></p>
</li>
<li><p>调用RunPodSandbox创建并启动Sandbox容器</p>
<ul>
<li><p>RunPodSandbox不同的CRI实现有不通</p>
</li>
<li><p>整体流程：</p>
<ul>
<li><ol>
<li>确保Sandbox容器镜像存在</li>
<li>根据传入的PodSandboxConfig创建Container对象</li>
<li>为Sandbox容器配置网络环境，包含调用CNI的ADD方法为Sandbox容器分配IP地址</li>
<li>调用底层OCI Runtime（如runc）启动Sandbox容器</li>
</ol>
<blockquote>
<p>CNI定义了容器IP地址分配和回收的标准接口，最核心的是ADD（IP分配）和DEL（IP释放）俩个操作</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kuberuntime/kuberuntime_sandbox.go#L40">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kuberuntime/kuberuntime_sandbox.go#L40</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// createPodSandbox creates a pod sandbox and returns (podSandBoxID, message, error).</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span></span> createPodSandbox(pod *v1.Pod, attempt <span class="type">uint32</span>) (<span class="type">string</span>, <span class="type">string</span>, <span class="type">error</span>) &#123;</span><br><span class="line">	podSandboxConfig, err := m.generatePodSandboxConfig(pod, attempt)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		message := fmt.Sprintf(<span class="string">&quot;Failed to generate sandbox config for pod %q: %v&quot;</span>, format.Pod(pod), err)</span><br><span class="line">		klog.ErrorS(err, <span class="string">&quot;Failed to generate sandbox config for pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span>, message, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Create pod logs directory</span></span><br><span class="line">	err = m.osInterface.MkdirAll(podSandboxConfig.LogDirectory, <span class="number">0755</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		message := fmt.Sprintf(<span class="string">&quot;Failed to create log directory for pod %q: %v&quot;</span>, format.Pod(pod), err)</span><br><span class="line">		klog.ErrorS(err, <span class="string">&quot;Failed to create log directory for pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span>, message, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	runtimeHandler := <span class="string">&quot;&quot;</span></span><br><span class="line">	<span class="keyword">if</span> m.runtimeClassManager != <span class="literal">nil</span> &#123;</span><br><span class="line">		runtimeHandler, err = m.runtimeClassManager.LookupRuntimeHandler(pod.Spec.RuntimeClassName)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			message := fmt.Sprintf(<span class="string">&quot;Failed to create sandbox for pod %q: %v&quot;</span>, format.Pod(pod), err)</span><br><span class="line">			<span class="keyword">return</span> <span class="string">&quot;&quot;</span>, message, err</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> runtimeHandler != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">			klog.V(<span class="number">2</span>).InfoS(<span class="string">&quot;Running pod with runtime handler&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;runtimeHandler&quot;</span>, runtimeHandler)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	podSandBoxID, err := m.runtimeService.RunPodSandbox(podSandboxConfig, runtimeHandler)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		message := fmt.Sprintf(<span class="string">&quot;Failed to create sandbox for pod %q: %v&quot;</span>, format.Pod(pod), err)</span><br><span class="line">		klog.ErrorS(err, <span class="string">&quot;Failed to create sandbox for pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod))</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span>, message, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> podSandBoxID, <span class="string">&quot;&quot;</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="调用CRI创建普通容器"><a href="#调用CRI创建普通容器" class="headerlink" title="调用CRI创建普通容器"></a>调用CRI创建普通容器</h3><p>在Sandbox隔离环境创建之后，kubelet接着启动普通容器，普通容器包含Ephemeral临时容器、Init容器以及Normal业务容器。</p>
<p>上面的三类容器都通过高satrt func启动</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kuberuntime/kuberuntime_manager.go#L848">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/kuberuntime/kuberuntime_manager.go#L848</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> msg, err := m.startContainer(podSandboxID, podSandboxConfig, spec, pod, podStatus, pullSecrets, podIP, podIPs); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="comment">// startContainer() returns well-defined error codes that have reasonable cardinality for metrics and are</span></span><br><span class="line">		<span class="comment">// useful to cluster administrators to distinguish &quot;server errors&quot; from &quot;user errors&quot;.</span></span><br><span class="line">		metrics.StartedContainersErrorsTotal.WithLabelValues(metricLabel, err.Error()).Inc()</span><br><span class="line">		<span class="keyword">if</span> sc.HasWindowsHostProcessRequest(pod, spec.container) &#123;</span><br><span class="line">			metrics.StartedHostProcessContainersErrorsTotal.WithLabelValues(metricLabel, err.Error()).Inc()</span><br><span class="line">		&#125;</span><br><span class="line">		startContainerResult.Fail(err, msg)</span><br><span class="line">		<span class="comment">// known errors that are logged in other places are logged at higher levels here to avoid</span></span><br><span class="line">		<span class="comment">// repetitive log spam</span></span><br><span class="line">		<span class="keyword">switch</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> err == images.ErrImagePullBackOff:</span><br><span class="line">			klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;Container start failed in pod&quot;</span>, <span class="string">&quot;containerType&quot;</span>, typeName, <span class="string">&quot;container&quot;</span>, spec.container, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;containerMessage&quot;</span>, msg, <span class="string">&quot;err&quot;</span>, err)</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			utilruntime.HandleError(fmt.Errorf(<span class="string">&quot;%v %+v start failed in pod %v: %v: %s&quot;</span>, typeName, spec.container, format.Pod(pod), err, msg))</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">  </span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Ref：<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/16da2955d0ffeb7fcdfd7148ef2fb6c1ce1a9ef5/pkg/kubelet/kuberuntime/kuberuntime_container.go#L196">https://github.com/kubernetes/kubernetes/blob/16da2955d0ffeb7fcdfd7148ef2fb6c1ce1a9ef5/pkg/kubelet/kuberuntime/kuberuntime_container.go#L196</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// startContainer starts a container and returns a message indicates why it is failed on error.</span></span><br><span class="line"><span class="comment">// It starts the container through the following steps:</span></span><br><span class="line"><span class="comment">// * pull the image</span></span><br><span class="line"><span class="comment">// * create the container</span></span><br><span class="line"><span class="comment">// * start the container</span></span><br><span class="line"><span class="comment">// * run the post start lifecycle hooks (if applicable)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span></span> startContainer(ctx context.Context, podSandboxID <span class="type">string</span>, podSandboxConfig *runtimeapi.PodSandboxConfig, spec *startSpec, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP <span class="type">string</span>, podIPs []<span class="type">string</span>, imageVolumes kubecontainer.ImageVolumes) (<span class="type">string</span>, <span class="type">error</span>) &#123;</span><br><span class="line">	container := spec.container</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Step 1: pull the image.</span></span><br><span class="line">	podRuntimeHandler, err := m.getPodRuntimeHandler(pod)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;&quot;</span>, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	ref, err := kubecontainer.GenerateContainerRef(pod, container)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		klog.ErrorS(err, <span class="string">&quot;Couldn&#x27;t make a ref to pod&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod), <span class="string">&quot;containerName&quot;</span>, container.Name)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	imageRef, msg, err := m.imagePuller.EnsureImageExists(ctx, ref, pod, container.Image, pullSecrets, podSandboxConfig, podRuntimeHandler, container.ImagePullPolicy)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		s, _ := grpcstatus.FromError(err)</span><br><span class="line">		m.recordContainerEvent(pod, container, <span class="string">&quot;&quot;</span>, v1.EventTypeWarning, events.FailedToCreateContainer, <span class="string">&quot;Error: %v&quot;</span>, s.Message())</span><br><span class="line">		<span class="keyword">return</span> msg, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Step 2: create the container.</span></span><br><span class="line">	<span class="comment">// For a new container, the RestartCount should be 0</span></span><br><span class="line">	restartCount := <span class="number">0</span></span><br><span class="line">	containerStatus := podStatus.FindContainerStatusByName(container.Name)</span><br><span class="line">	<span class="keyword">if</span> containerStatus != <span class="literal">nil</span> &#123;</span><br><span class="line">		restartCount = containerStatus.RestartCount + <span class="number">1</span></span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// The container runtime keeps state on container statuses and</span></span><br><span class="line">		<span class="comment">// what the container restart count is. When nodes are rebooted</span></span><br><span class="line">		<span class="comment">// some container runtimes clear their state which causes the</span></span><br><span class="line">		<span class="comment">// restartCount to be reset to 0. This causes the logfile to</span></span><br><span class="line">		<span class="comment">// start at 0.log, which either overwrites or appends to the</span></span><br><span class="line">		<span class="comment">// already existing log.</span></span><br><span class="line">		<span class="comment">//</span></span><br><span class="line">		<span class="comment">// We are checking to see if the log directory exists, and find</span></span><br><span class="line">		<span class="comment">// the latest restartCount by checking the log name -</span></span><br><span class="line">		<span class="comment">// &#123;restartCount&#125;.log - and adding 1 to it.</span></span><br><span class="line">		logDir := BuildContainerLogsDirectory(m.podLogsDirectory, pod.Namespace, pod.Name, pod.UID, container.Name)</span><br><span class="line">		restartCount, err = calcRestartCountByLogDir(logDir)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			klog.InfoS(<span class="string">&quot;Cannot calculate restartCount from the log directory&quot;</span>, <span class="string">&quot;logDir&quot;</span>, logDir, <span class="string">&quot;err&quot;</span>, err)</span><br><span class="line">			restartCount = <span class="number">0</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	target, err := spec.getTargetID(podStatus)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		s, _ := grpcstatus.FromError(err)</span><br><span class="line">		m.recordContainerEvent(pod, container, <span class="string">&quot;&quot;</span>, v1.EventTypeWarning, events.FailedToCreateContainer, <span class="string">&quot;Error: %v&quot;</span>, s.Message())</span><br><span class="line">		<span class="keyword">return</span> s.Message(), ErrCreateContainerConfig</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	containerConfig, cleanupAction, err := m.generateContainerConfig(ctx, container, pod, restartCount, podIP, imageRef, podIPs, target, imageVolumes)</span><br><span class="line">	<span class="keyword">if</span> cleanupAction != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">defer</span> cleanupAction()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		s, _ := grpcstatus.FromError(err)</span><br><span class="line">		m.recordContainerEvent(pod, container, <span class="string">&quot;&quot;</span>, v1.EventTypeWarning, events.FailedToCreateContainer, <span class="string">&quot;Error: %v&quot;</span>, s.Message())</span><br><span class="line">		<span class="keyword">return</span> s.Message(), ErrCreateContainerConfig</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = m.internalLifecycle.PreCreateContainer(pod, container, containerConfig)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		s, _ := grpcstatus.FromError(err)</span><br><span class="line">		m.recordContainerEvent(pod, container, <span class="string">&quot;&quot;</span>, v1.EventTypeWarning, events.FailedToCreateContainer, <span class="string">&quot;Internal PreCreateContainer hook failed: %v&quot;</span>, s.Message())</span><br><span class="line">		<span class="keyword">return</span> s.Message(), ErrPreCreateHook</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	containerID, err := m.runtimeService.CreateContainer(ctx, podSandboxID, containerConfig, podSandboxConfig)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		s, _ := grpcstatus.FromError(err)</span><br><span class="line">		m.recordContainerEvent(pod, container, containerID, v1.EventTypeWarning, events.FailedToCreateContainer, <span class="string">&quot;Error: %v&quot;</span>, s.Message())</span><br><span class="line">		<span class="keyword">return</span> s.Message(), ErrCreateContainer</span><br><span class="line">	&#125;</span><br><span class="line">	err = m.internalLifecycle.PreStartContainer(pod, container, containerID)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		s, _ := grpcstatus.FromError(err)</span><br><span class="line">		m.recordContainerEvent(pod, container, containerID, v1.EventTypeWarning, events.FailedToStartContainer, <span class="string">&quot;Internal PreStartContainer hook failed: %v&quot;</span>, s.Message())</span><br><span class="line">		<span class="keyword">return</span> s.Message(), ErrPreStartHook</span><br><span class="line">	&#125;</span><br><span class="line">	m.recordContainerEvent(pod, container, containerID, v1.EventTypeNormal, events.CreatedContainer, <span class="string">&quot;Created container: %v&quot;</span>, container.Name)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Step 3: start the container.</span></span><br><span class="line">	err = m.runtimeService.StartContainer(ctx, containerID)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		s, _ := grpcstatus.FromError(err)</span><br><span class="line">		m.recordContainerEvent(pod, container, containerID, v1.EventTypeWarning, events.FailedToStartContainer, <span class="string">&quot;Error: %v&quot;</span>, s.Message())</span><br><span class="line">		<span class="keyword">return</span> s.Message(), kubecontainer.ErrRunContainer</span><br><span class="line">	&#125;</span><br><span class="line">	m.recordContainerEvent(pod, container, containerID, v1.EventTypeNormal, events.StartedContainer, <span class="string">&quot;Started container %v&quot;</span>, container.Name)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Symlink container logs to the legacy container log location for cluster logging</span></span><br><span class="line">	<span class="comment">// support.</span></span><br><span class="line">	<span class="comment">// TODO(random-liu): Remove this after cluster logging supports CRI container log path.</span></span><br><span class="line">	containerMeta := containerConfig.GetMetadata()</span><br><span class="line">	sandboxMeta := podSandboxConfig.GetMetadata()</span><br><span class="line">	legacySymlink := legacyLogSymlink(containerID, containerMeta.Name, sandboxMeta.Name,</span><br><span class="line">		sandboxMeta.Namespace)</span><br><span class="line">	containerLog := filepath.Join(podSandboxConfig.LogDirectory, containerConfig.LogPath)</span><br><span class="line">	<span class="comment">// only create legacy symlink if containerLog path exists (or the error is not IsNotExist).</span></span><br><span class="line">	<span class="comment">// Because if containerLog path does not exist, only dangling legacySymlink is created.</span></span><br><span class="line">	<span class="comment">// This dangling legacySymlink is later removed by container gc, so it does not make sense</span></span><br><span class="line">	<span class="comment">// to create it in the first place. it happens when journald logging driver is used with docker.</span></span><br><span class="line">	<span class="keyword">if</span> _, err := m.osInterface.Stat(containerLog); !os.IsNotExist(err) &#123;</span><br><span class="line">		<span class="keyword">if</span> err := m.osInterface.Symlink(containerLog, legacySymlink); err != <span class="literal">nil</span> &#123;</span><br><span class="line">			klog.ErrorS(err, <span class="string">&quot;Failed to create legacy symbolic link&quot;</span>, <span class="string">&quot;path&quot;</span>, legacySymlink,</span><br><span class="line">				<span class="string">&quot;containerID&quot;</span>, containerID, <span class="string">&quot;containerLogPath&quot;</span>, containerLog)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Step 4: execute the post start hook.</span></span><br><span class="line">	<span class="keyword">if</span> container.Lifecycle != <span class="literal">nil</span> &amp;&amp; container.Lifecycle.PostStart != <span class="literal">nil</span> &#123;</span><br><span class="line">		kubeContainerID := kubecontainer.ContainerID&#123;</span><br><span class="line">			Type: m.runtimeName,</span><br><span class="line">			ID:   containerID,</span><br><span class="line">		&#125;</span><br><span class="line">		msg, handlerErr := m.runner.Run(ctx, kubeContainerID, pod, container, container.Lifecycle.PostStart)</span><br><span class="line">		<span class="keyword">if</span> handlerErr != <span class="literal">nil</span> &#123;</span><br><span class="line">			klog.ErrorS(handlerErr, <span class="string">&quot;Failed to execute PostStartHook&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod),</span><br><span class="line">				<span class="string">&quot;podUID&quot;</span>, pod.UID, <span class="string">&quot;containerName&quot;</span>, container.Name, <span class="string">&quot;containerID&quot;</span>, kubeContainerID.String())</span><br><span class="line">			<span class="comment">// do not record the message in the event so that secrets won&#x27;t leak from the server.</span></span><br><span class="line">			m.recordContainerEvent(pod, container, kubeContainerID.ID, v1.EventTypeWarning, events.FailedPostStartHook, <span class="string">&quot;PostStartHook failed&quot;</span>)</span><br><span class="line">			<span class="keyword">if</span> err := m.killContainer(ctx, pod, kubeContainerID, container.Name, <span class="string">&quot;FailedPostStartHook&quot;</span>, reasonFailedPostStartHook, <span class="literal">nil</span>, <span class="literal">nil</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">				klog.ErrorS(err, <span class="string">&quot;Failed to kill container&quot;</span>, <span class="string">&quot;pod&quot;</span>, klog.KObj(pod),</span><br><span class="line">					<span class="string">&quot;podUID&quot;</span>, pod.UID, <span class="string">&quot;containerName&quot;</span>, container.Name, <span class="string">&quot;containerID&quot;</span>, kubeContainerID.String())</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> msg, ErrPostStartHook</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="string">&quot;&quot;</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于普通容器共享Sandbox隔离环境的Network、IPC、UTS等命名空间，创建普通容器等过程如下：</p>
<ol>
<li>确保运行容器镜像存在，如果不存在，尝试主动拉取</li>
<li>调用CRI的CreateContainer创建容器，并且绑定Sandbox隔离环境</li>
<li>调用CRI的StartContainer启动容器，底层通过OCI runtime完成</li>
<li>如果容器配置了PostStart Hook，则通过runner.Run调用执行</li>
</ol>
</li>
</ul>
<h2 id="Pod驱逐流程"><a href="#Pod驱逐流程" class="headerlink" title="Pod驱逐流程"></a>Pod驱逐流程</h2><p>为了保证节点的稳定性以及Pod QoS，kubelet会在节点资源不足的情况，按照一定的的策略驱逐Pod，确保节点上的资源得到最佳利用</p>
<p>kubelet驱逐Pod的场景主要包含俩类：</p>
<ul>
<li>Critical Pod被调度到节点，因资源竞争，触发对低有优先级的Pod的驱逐</li>
<li>在节点资源紧张的时候，为了保证节点的稳定性，触发对低优先级的Pod的驱逐</li>
</ul>
<h3 id="Critical-Pod被调度到节点，因资源竞争，触发对低有优先级的Pod的驱逐"><a href="#Critical-Pod被调度到节点，因资源竞争，触发对低有优先级的Pod的驱逐" class="headerlink" title="Critical Pod被调度到节点，因资源竞争，触发对低有优先级的Pod的驱逐"></a>Critical Pod被调度到节点，因资源竞争，触发对低有优先级的Pod的驱逐</h3><p>触发驱逐的核心逻辑是：CriticalPodAdmissionHandler</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/3ec97a445f036a38bfec6291dee661954138bac9/pkg/kubelet/preemption/preemption.go#L63">https://github.com/kubernetes/kubernetes/blob/3ec97a445f036a38bfec6291dee661954138bac9/pkg/kubelet/preemption/preemption.go#L63</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// HandleAdmissionFailure gracefully handles admission rejection, and, in some cases,</span></span><br><span class="line"><span class="comment">// to allow admission of the pod despite its previous failure.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *CriticalPodAdmissionHandler)</span></span> HandleAdmissionFailure(admitPod *v1.Pod, failureReasons []lifecycle.PredicateFailureReason) ([]lifecycle.PredicateFailureReason, <span class="type">error</span>) &#123;</span><br><span class="line">	<span class="keyword">if</span> !kubetypes.IsCriticalPod(admitPod) &#123;</span><br><span class="line">		<span class="keyword">return</span> failureReasons, <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// InsufficientResourceError is not a reason to reject a critical pod.</span></span><br><span class="line">	<span class="comment">// Instead of rejecting, we free up resources to admit it, if no other reasons for rejection exist.</span></span><br><span class="line">	nonResourceReasons := []lifecycle.PredicateFailureReason&#123;&#125;</span><br><span class="line">	resourceReasons := []*admissionRequirement&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> _, reason := <span class="keyword">range</span> failureReasons &#123;</span><br><span class="line">		<span class="keyword">if</span> r, ok := reason.(*lifecycle.InsufficientResourceError); ok &#123;</span><br><span class="line">			resourceReasons = <span class="built_in">append</span>(resourceReasons, &amp;admissionRequirement&#123;</span><br><span class="line">				resourceName: r.ResourceName,</span><br><span class="line">				quantity:     r.GetInsufficientAmount(),</span><br><span class="line">			&#125;)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			nonResourceReasons = <span class="built_in">append</span>(nonResourceReasons, reason)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(nonResourceReasons) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="comment">// Return only reasons that are not resource related, since critical pods cannot fail admission for resource reasons.</span></span><br><span class="line">		<span class="keyword">return</span> nonResourceReasons, <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	err := c.evictPodsToFreeRequests(admitPod, admissionRequirementList(resourceReasons))</span><br><span class="line">	<span class="comment">// if no error is returned, preemption succeeded and the pod is safe to admit.</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>kubelet选择最低优先级的Pod作为驱逐对象遵循一定的策略</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/3ec97a445f036a38bfec6291dee661954138bac9/pkg/kubelet/preemption/preemption.go#L130">https://github.com/kubernetes/kubernetes/blob/3ec97a445f036a38bfec6291dee661954138bac9/pkg/kubelet/preemption/preemption.go#L130</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// getPodsToPreempt returns a list of pods that could be preempted to free requests &gt;= requirements</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getPodsToPreempt</span><span class="params">(pod *v1.Pod, pods []*v1.Pod, requirements admissionRequirementList)</span></span> ([]*v1.Pod, <span class="type">error</span>) &#123;</span><br><span class="line">	bestEffortPods, burstablePods, guaranteedPods := sortPodsByQOS(pod, pods)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// make sure that pods exist to reclaim the requirements</span></span><br><span class="line">	unableToMeetRequirements := requirements.subtract(<span class="built_in">append</span>(<span class="built_in">append</span>(bestEffortPods, burstablePods...), guaranteedPods...)...)</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(unableToMeetRequirements) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;no set of running pods found to reclaim resources: %v&quot;</span>, unableToMeetRequirements.toString())</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// find the guaranteed pods we would need to evict if we already evicted ALL burstable and besteffort pods.</span></span><br><span class="line">	guaranteedToEvict, err := getPodsToPreemptByDistance(guaranteedPods, requirements.subtract(<span class="built_in">append</span>(bestEffortPods, burstablePods...)...))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// Find the burstable pods we would need to evict if we already evicted ALL besteffort pods, and the required guaranteed pods.</span></span><br><span class="line">	burstableToEvict, err := getPodsToPreemptByDistance(burstablePods, requirements.subtract(<span class="built_in">append</span>(bestEffortPods, guaranteedToEvict...)...))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// Find the besteffort pods we would need to evict if we already evicted the required guaranteed and burstable pods.</span></span><br><span class="line">	bestEffortToEvict, err := getPodsToPreemptByDistance(bestEffortPods, requirements.subtract(<span class="built_in">append</span>(burstableToEvict, guaranteedToEvict...)...))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">append</span>(<span class="built_in">append</span>(bestEffortToEvict, burstableToEvict...), guaranteedToEvict...), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体计算逻辑如下：</p>
<ol>
<li><p>筛选出节点上优先级低于当前运行Pod的Pod列表（Critial Pod优先级高于非Critial Pod，Priority值大的Pod优先级高于Prioity值小的Pod</p>
</li>
<li><p>将筛选出的Pod列表，按照Pod的QoS分为三类，即BestEffort、Burstable和Guaranteed</p>
</li>
<li><p>判断驱逐当前统计出的可驱逐Pod列表中的Pod能释放的资源总和能否满足待运行的Pod的需求，如果不能，则返回错误，不触发后续驱逐操作</p>
</li>
<li><p>假设所有的BestEffort Pod和Butstable Pod已经全部被驱逐，占用的资源得到释放，则计算剩余资源需要驱逐的Guraranteed Pod列表。在选择Pod时，遍历候选的Pod列表，依次计算驱逐每个Pod能释放的资源和所需资源的距离，距离越小表示驱逐当前的Pod越能满足所需资源。每次都选择距离最小的Pod作为驱逐对象，并且添加到待驱逐列表。</p>
<ul>
<li>当同时存在多个Pod能释放的资源与所需要的资源的距离计算结果相同，优先选择资源占用更小的Pod</li>
</ul>
</li>
<li><p>假设所有的BestEffort Pod和计算出的需要驱逐的Guaranteed Pod已经全部被驱逐，占用的资源假设得到释放，计算释放剩余资源需要驱逐的BestEffort Pod列表</p>
</li>
<li><p>假设需要驱逐的Guaranteed Pod和Burstable Pod已经全部被驱逐，占用的资源得到释放，则计算释放剩余资源需要驱逐的Besteffort Pod列表</p>
</li>
<li><p>将前面几步计算得出驱逐的Pod叠加，按照BestEffort、Burstable、Guaranteed的顺序排序，作为最终的带驱逐的Pod列表</p>
<p>整体，选择待驱逐的Pod，还是遵循QoS等级，按咋后BestEffort\Burstable\Guarantedd顺序，同时采用资源距离算法尽可撒后减少驱逐Pod的数量</p>
</li>
</ol>
<h3 id="在节点资源紧张的时候，为了保证节点的稳定性，触发对低优先级的Pod的驱逐"><a href="#在节点资源紧张的时候，为了保证节点的稳定性，触发对低优先级的Pod的驱逐" class="headerlink" title="在节点资源紧张的时候，为了保证节点的稳定性，触发对低优先级的Pod的驱逐"></a>在节点资源紧张的时候，为了保证节点的稳定性，触发对低优先级的Pod的驱逐</h3><p>kubelet使用EvictionManager监控节点的资源使用情况，包含内存、存储、PID等，当节点存在资源压力的，主动驱逐Pod释放资源，确保节点工作稳定</p>
<p><img src="https://raw.githubusercontent.com/Piwriw/PicGo/master/image202412172329456.png"></p>
</li>
</ul>
<p>EvictionManager每间隔10s轮询Eviction Signal驱逐信号，并且与设置的Thresholds阈值比较，当满足驱逐条件的时候，从Active Pods按照一定的规则策略选择需要驱逐的Pod进行比较，因节点资源压力导致的驱逐在每个执行周期最多驱逐一个Pod，不会批量驱逐。</p>
<blockquote>
<p>为了提高对内存变化的感知速度，EvictionManager使用内存用量监听，使用MemoryThresholdNotifier监听cgroups memcg event事件，通过基于事件触发的模式降低每隔10s轮询的延迟</p>
</blockquote>
<p>kubelet支持俩种驱逐类型：硬驱逐和软驱逐</p>
<h4 id="硬驱逐相关参数"><a href="#硬驱逐相关参数" class="headerlink" title="硬驱逐相关参数"></a>硬驱逐相关参数</h4><ul>
<li><code>--eviction-hard</code>：硬驱逐阈值，当资源压力达到阈值，立即触发硬驱逐，此时Pod的优雅停机时间会被忽略，直接发送Kill信号，默认值为imagefs.available&lt;15%,memory.available&lt;100Mi,nodefs.available&lt;10%</li>
</ul>
<h4 id="软驱逐相关参数"><a href="#软驱逐相关参数" class="headerlink" title="软驱逐相关参数"></a>软驱逐相关参数</h4><ul>
<li><code>--eviction-soft</code>:软驱逐阈值，当资源达到阈值，触发软驱逐，此刻不会立即终止Pod，而是等待<code>eviction-sofe-grace-period</code>时间后，资源压力任然触发，才会执行Pod驱逐</li>
<li><code>eviction-sofe-grace-period</code>:软驱逐的优雅等待时间，防止因为抖动导致驱逐</li>
<li><code>--eviction-max-pod-grace-period</code>:软驱逐的最大优雅停机等待时间。如果待驱逐的Pod已经设置了TerminationGradePeriodSeconds，则会选择Pod优雅停机等待时间和软驱逐的优雅停机等待时间的最小作为，而时间上直接用了软驱逐的优雅等待时间，这是一个已知道问题issue#64530</li>
</ul>
<h4 id="公共参数"><a href="#公共参数" class="headerlink" title="公共参数"></a>公共参数</h4><ul>
<li><code>--eviction-minimum-reclaim</code>:驱逐最小回收量。在某些情况下，驱逐Pod只会回收少量的紧俏资源，这可能导致kubelet反复达到配置的驱逐条件并多次触发驱逐，可以通过该配置为每类资源资源的最小回收量</li>
<li><code>--eviction-pressure-transition-period</code>:节点状态转换等待时间。在某些情况下，节点在软驱逐条件上上下振荡，这会导致报告节点状态一直在true和false转换，导致错误的驱逐错误。为了防止振荡，可以设置该参数在节点转换的等待时间，默认5min</li>
<li><code>--kernel-memcg-notification</code>:启用内核的memcg通知机制。在默认情况下，kubelet轮询cAdvisor以定期收集内存使用情况统计信息，这可能不及时。通过启用memcg通知，可以在内存超过阈值的时候，kubelet立即感知到压力，触发驱逐</li>
</ul>
<p>工作机制上，EvictionManager通过内部协程持续监测节点资源使用情况，默认10s一次探测：</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/eviction/eviction_manager.go#L178">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/eviction/eviction_manager.go#L178</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Start starts the control loop to observe and response to low compute resources.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *managerImpl)</span></span> Start(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc, podCleanedUpFunc PodCleanedUpFunc, monitoringInterval time.Duration) &#123;</span><br><span class="line">	thresholdHandler := <span class="function"><span class="keyword">func</span><span class="params">(message <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">		klog.InfoS(message)</span><br><span class="line">		m.synchronize(diskInfoProvider, podFunc)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> m.config.KernelMemcgNotification &#123;</span><br><span class="line">		<span class="keyword">for</span> _, threshold := <span class="keyword">range</span> m.config.Thresholds &#123;</span><br><span class="line">			<span class="keyword">if</span> threshold.Signal == evictionapi.SignalMemoryAvailable || threshold.Signal == evictionapi.SignalAllocatableMemoryAvailable &#123;</span><br><span class="line">				notifier, err := NewMemoryThresholdNotifier(threshold, m.config.PodCgroupRoot, &amp;CgroupNotifierFactory&#123;&#125;, thresholdHandler)</span><br><span class="line">				<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">					klog.InfoS(<span class="string">&quot;Eviction manager: failed to create memory threshold notifier&quot;</span>, <span class="string">&quot;err&quot;</span>, err)</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					<span class="keyword">go</span> notifier.Start()</span><br><span class="line">					m.thresholdNotifiers = <span class="built_in">append</span>(m.thresholdNotifiers, notifier)</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// start the eviction manager monitoring</span></span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">for</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> evictedPods := m.synchronize(diskInfoProvider, podFunc); evictedPods != <span class="literal">nil</span> &#123;</span><br><span class="line">				klog.InfoS(<span class="string">&quot;Eviction manager: pods evicted, waiting for pod to be cleaned up&quot;</span>, <span class="string">&quot;pods&quot;</span>, klog.KObjs(evictedPods))</span><br><span class="line">				m.waitForPodsCleanup(podCleanedUpFunc, evictedPods)</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				time.Sleep(monitoringInterval)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>synchronize是驱逐探测的核心逻辑；</p>
<ul>
<li><p>Ref:<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/eviction/eviction_manager.go#L232">https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/pkg/kubelet/eviction/eviction_manager.go#L232</a></p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// synchronize is the main control loop that enforces eviction thresholds.</span></span><br><span class="line"><span class="comment">// Returns the pod that was killed, or nil if no pod was killed.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *managerImpl)</span></span> synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod &#123;</span><br><span class="line">	<span class="comment">// if we have nothing to do, just return</span></span><br><span class="line">	thresholds := m.config.Thresholds</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(thresholds) == <span class="number">0</span> &amp;&amp; !m.localStorageCapacityIsolation &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;Eviction manager: synchronize housekeeping&quot;</span>)</span><br><span class="line">	<span class="comment">// build the ranking functions (if not yet known)</span></span><br><span class="line">	<span class="comment">// <span class="doctag">TODO:</span> have a function in cadvisor that lets us know if global housekeeping has completed</span></span><br><span class="line">	<span class="keyword">if</span> m.dedicatedImageFs == <span class="literal">nil</span> &#123;</span><br><span class="line">		hasImageFs, ok := diskInfoProvider.HasDedicatedImageFs()</span><br><span class="line">		<span class="keyword">if</span> ok != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">		m.dedicatedImageFs = &amp;hasImageFs</span><br><span class="line">		m.signalToRankFunc = buildSignalToRankFunc(hasImageFs)</span><br><span class="line">		m.signalToNodeReclaimFuncs = buildSignalToNodeReclaimFuncs(m.imageGC, m.containerGC, hasImageFs)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	activePods := podFunc()</span><br><span class="line">	updateStats := <span class="literal">true</span></span><br><span class="line">	summary, err := m.summaryProvider.Get(updateStats)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		klog.ErrorS(err, <span class="string">&quot;Eviction manager: failed to get summary stats&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> m.clock.Since(m.thresholdsLastUpdated) &gt; notifierRefreshInterval &#123;</span><br><span class="line">		m.thresholdsLastUpdated = m.clock.Now()</span><br><span class="line">		<span class="keyword">for</span> _, notifier := <span class="keyword">range</span> m.thresholdNotifiers &#123;</span><br><span class="line">			<span class="keyword">if</span> err := notifier.UpdateThreshold(summary); err != <span class="literal">nil</span> &#123;</span><br><span class="line">				klog.InfoS(<span class="string">&quot;Eviction manager: failed to update notifier&quot;</span>, <span class="string">&quot;notifier&quot;</span>, notifier.Description(), <span class="string">&quot;err&quot;</span>, err)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// make observations and get a function to derive pod usage stats relative to those observations.</span></span><br><span class="line">	observations, statsFunc := makeSignalObservations(summary)</span><br><span class="line">	debugLogObservations(<span class="string">&quot;observations&quot;</span>, observations)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// determine the set of thresholds met independent of grace period</span></span><br><span class="line">	thresholds = thresholdsMet(thresholds, observations, <span class="literal">false</span>)</span><br><span class="line">	debugLogThresholdsWithObservation(<span class="string">&quot;thresholds - ignoring grace period&quot;</span>, thresholds, observations)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// determine the set of thresholds previously met that have not yet satisfied the associated min-reclaim</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(m.thresholdsMet) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		thresholdsNotYetResolved := thresholdsMet(m.thresholdsMet, observations, <span class="literal">true</span>)</span><br><span class="line">		thresholds = mergeThresholds(thresholds, thresholdsNotYetResolved)</span><br><span class="line">	&#125;</span><br><span class="line">	debugLogThresholdsWithObservation(<span class="string">&quot;thresholds - reclaim not satisfied&quot;</span>, thresholds, observations)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// track when a threshold was first observed</span></span><br><span class="line">	now := m.clock.Now()</span><br><span class="line">	thresholdsFirstObservedAt := thresholdsFirstObservedAt(thresholds, m.thresholdsFirstObservedAt, now)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// the set of node conditions that are triggered by currently observed thresholds</span></span><br><span class="line">	nodeConditions := nodeConditions(thresholds)</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(nodeConditions) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;Eviction manager: node conditions - observed&quot;</span>, <span class="string">&quot;nodeCondition&quot;</span>, nodeConditions)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// track when a node condition was last observed</span></span><br><span class="line">	nodeConditionsLastObservedAt := nodeConditionsLastObservedAt(nodeConditions, m.nodeConditionsLastObservedAt, now)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// node conditions report true if it has been observed within the transition period window</span></span><br><span class="line">	nodeConditions = nodeConditionsObservedSince(nodeConditionsLastObservedAt, m.config.PressureTransitionPeriod, now)</span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(nodeConditions) &gt; <span class="number">0</span> &#123;</span><br><span class="line">		klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;Eviction manager: node conditions - transition period not met&quot;</span>, <span class="string">&quot;nodeCondition&quot;</span>, nodeConditions)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// determine the set of thresholds we need to drive eviction behavior (i.e. all grace periods are met)</span></span><br><span class="line">	thresholds = thresholdsMetGracePeriod(thresholdsFirstObservedAt, now)</span><br><span class="line">	debugLogThresholdsWithObservation(<span class="string">&quot;thresholds - grace periods satisfied&quot;</span>, thresholds, observations)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// update internal state</span></span><br><span class="line">	m.Lock()</span><br><span class="line">	m.nodeConditions = nodeConditions</span><br><span class="line">	m.thresholdsFirstObservedAt = thresholdsFirstObservedAt</span><br><span class="line">	m.nodeConditionsLastObservedAt = nodeConditionsLastObservedAt</span><br><span class="line">	m.thresholdsMet = thresholds</span><br><span class="line"></span><br><span class="line">	<span class="comment">// determine the set of thresholds whose stats have been updated since the last sync</span></span><br><span class="line">	thresholds = thresholdsUpdatedStats(thresholds, observations, m.lastObservations)</span><br><span class="line">	debugLogThresholdsWithObservation(<span class="string">&quot;thresholds - updated stats&quot;</span>, thresholds, observations)</span><br><span class="line"></span><br><span class="line">	m.lastObservations = observations</span><br><span class="line">	m.Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// evict pods if there is a resource usage violation from local volume temporary storage</span></span><br><span class="line">	<span class="comment">// If eviction happens in localStorageEviction function, skip the rest of eviction action</span></span><br><span class="line">	<span class="keyword">if</span> m.localStorageCapacityIsolation &#123;</span><br><span class="line">		<span class="keyword">if</span> evictedPods := m.localStorageEviction(activePods, statsFunc); <span class="built_in">len</span>(evictedPods) &gt; <span class="number">0</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> evictedPods</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(thresholds) == <span class="number">0</span> &#123;</span><br><span class="line">		klog.V(<span class="number">3</span>).InfoS(<span class="string">&quot;Eviction manager: no resources are starved&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// rank the thresholds by eviction priority</span></span><br><span class="line">	sort.Sort(byEvictionPriority(thresholds))</span><br><span class="line">	thresholdToReclaim, resourceToReclaim, foundAny := getReclaimableThreshold(thresholds)</span><br><span class="line">	<span class="keyword">if</span> !foundAny &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line">	klog.InfoS(<span class="string">&quot;Eviction manager: attempting to reclaim&quot;</span>, <span class="string">&quot;resourceName&quot;</span>, resourceToReclaim)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// record an event about the resources we are now attempting to reclaim via eviction</span></span><br><span class="line">	m.recorder.Eventf(m.nodeRef, v1.EventTypeWarning, <span class="string">&quot;EvictionThresholdMet&quot;</span>, <span class="string">&quot;Attempting to reclaim %s&quot;</span>, resourceToReclaim)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// check if there are node-level resources we can reclaim to reduce pressure before evicting end-user pods.</span></span><br><span class="line">	<span class="keyword">if</span> m.reclaimNodeLevelResources(thresholdToReclaim.Signal, resourceToReclaim) &#123;</span><br><span class="line">		klog.InfoS(<span class="string">&quot;Eviction manager: able to reduce resource pressure without evicting pods.&quot;</span>, <span class="string">&quot;resourceName&quot;</span>, resourceToReclaim)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	klog.InfoS(<span class="string">&quot;Eviction manager: must evict pod(s) to reclaim&quot;</span>, <span class="string">&quot;resourceName&quot;</span>, resourceToReclaim)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// rank the pods for eviction</span></span><br><span class="line">	rank, ok := m.signalToRankFunc[thresholdToReclaim.Signal]</span><br><span class="line">	<span class="keyword">if</span> !ok &#123;</span><br><span class="line">		klog.ErrorS(<span class="literal">nil</span>, <span class="string">&quot;Eviction manager: no ranking function for signal&quot;</span>, <span class="string">&quot;threshold&quot;</span>, thresholdToReclaim.Signal)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// the only candidates viable for eviction are those pods that had anything running.</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(activePods) == <span class="number">0</span> &#123;</span><br><span class="line">		klog.ErrorS(<span class="literal">nil</span>, <span class="string">&quot;Eviction manager: eviction thresholds have been met, but no pods are active to evict&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// rank the running pods for eviction for the specified resource</span></span><br><span class="line">	rank(activePods, statsFunc)</span><br><span class="line"></span><br><span class="line">	klog.InfoS(<span class="string">&quot;Eviction manager: pods ranked for eviction&quot;</span>, <span class="string">&quot;pods&quot;</span>, klog.KObjs(activePods))</span><br><span class="line"></span><br><span class="line">	<span class="comment">//record age of metrics for met thresholds that we are using for evictions.</span></span><br><span class="line">	<span class="keyword">for</span> _, t := <span class="keyword">range</span> thresholds &#123;</span><br><span class="line">		timeObserved := observations[t.Signal].time</span><br><span class="line">		<span class="keyword">if</span> !timeObserved.IsZero() &#123;</span><br><span class="line">			metrics.EvictionStatsAge.WithLabelValues(<span class="type">string</span>(t.Signal)).Observe(metrics.SinceInSeconds(timeObserved.Time))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// we kill at most a single pod during each eviction interval</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> activePods &#123;</span><br><span class="line">		pod := activePods[i]</span><br><span class="line">		gracePeriodOverride := <span class="type">int64</span>(<span class="number">0</span>)</span><br><span class="line">		<span class="keyword">if</span> !isHardEvictionThreshold(thresholdToReclaim) &#123;</span><br><span class="line">			gracePeriodOverride = m.config.MaxPodGracePeriodSeconds</span><br><span class="line">		&#125;</span><br><span class="line">		message, annotations := evictionMessage(resourceToReclaim, pod, statsFunc)</span><br><span class="line">		<span class="keyword">if</span> m.evictPod(pod, gracePeriodOverride, message, annotations) &#123;</span><br><span class="line">			metrics.Evictions.WithLabelValues(<span class="type">string</span>(thresholdToReclaim.Signal)).Inc()</span><br><span class="line">			<span class="keyword">return</span> []*v1.Pod&#123;pod&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	klog.InfoS(<span class="string">&quot;Eviction manager: unable to evict any pods from the node&quot;</span>)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过makeSignalObserations计算当前观测到的驱逐信号（资源使用），kubelet支持的驱逐信号如下</p>
<table>
<thead>
<tr>
<th align="center">驱逐信号</th>
<th align="center">描述</th>
<th align="center">计算公式</th>
</tr>
</thead>
<tbody><tr>
<td align="center">memory.available</td>
<td align="center">节点可用内存</td>
<td align="center">memory.available&#x3D;node.status.capacity[memory]-node.status.memory.workingSet</td>
</tr>
<tr>
<td align="center">allocatableMemory.available</td>
<td align="center">留给Pod用的可用内存，仅当Node Allocatable Enforcemennts包含pods时起作用，默认为enforceNodeAllocatable&#x3D;[“pods”]</td>
<td align="center">allocateableMemory.available:&#x3D;pod.allocatable-pod.workingSet</td>
</tr>
<tr>
<td align="center">nodefs.avaiable</td>
<td align="center">kubelet使用的文件系统的可用容量</td>
<td align="center">nodefs.available:&#x3D;node.stats.fs.available</td>
</tr>
<tr>
<td align="center">nodefs.innodesFree</td>
<td align="center">kubelet使用的文件系统的可用inodes数量</td>
<td align="center">nodefs.innodesFree:&#x3D;node.stats.runtime.imagefs.available</td>
</tr>
<tr>
<td align="center">imagefs.available</td>
<td align="center">容器运行时用来存放镜像以及容器可写层的文件系统可用容量</td>
<td align="center">imagefs.available:&#x3D;node.stats.runtime.imagefs.available</td>
</tr>
<tr>
<td align="center">imagesfs.indoesFree</td>
<td align="center">容器运行时用来存放镜像以及容器可写层的文件系统的inodes数量</td>
<td align="center">imagefs.inodesFree:&#x3D;node.stats.runtime.imagefs.inodesFree</td>
</tr>
<tr>
<td align="center">pid.available</td>
<td align="center">留给分配Pod使用的可用PID</td>
<td align="center">pid.available:&#x3D;node.stats.rlimit.maxpid-node.stats.rlimit.curproc</td>
</tr>
</tbody></table>
<p>Pod可分配资源并不一定与节点剩余可用资源一致，为了保证系统的稳定性，一般会为系统守护进程保留资源。</p>
<ul>
<li>Pod可用资源：节点总可用资源-<code>kube-reserved</code>-<code>system-reserved</code>-<code>eviction-threshold</code><ul>
<li>kube-reserved:运行kubelet、Container Runtime等K8s系统服务保留资源</li>
<li>system-reserved：运行操作系统内核、sshd等系统服务需要保留的资源</li>
<li>eviction-threshold：驱逐设置的保留资源</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>​	</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/Piwriw">Joohwan.</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://piwriw.github.io/2024/12/13/cloud/k8s/kubelet/K8s-kubelet(Pod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86)/">https://piwriw.github.io/2024/12/13/cloud/k8s/kubelet/K8s-kubelet(Pod生命周期管理)/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://piwriw.github.io" target="_blank">Joohwan</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/k8s/">k8s</a><a class="post-meta__tags" href="/tags/cloud/">cloud</a><a class="post-meta__tags" href="/tags/K8s%E6%BA%90%E7%A0%81/">K8s源码</a><a class="post-meta__tags" href="/tags/kubelet/">kubelet</a></div><div class="post-share"><div class="social-share" data-image="/img/k8sLogo.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/12/14/cloud/k8s/kubelet/K8s-kubelet(Cgroup%E8%B5%84%E6%BA%90%E9%9A%94%E7%A6%BB%E4%BB%A5%E5%8F%8A%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%8E%9F%E7%90%86)/" title="K8s-kubelet(Cgroup资源隔离以及垃圾回收原理)"><img class="cover" src="/img/k8sLogo.png" onerror="onerror=null;src='/img/404.png'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">K8s-kubelet(Cgroup资源隔离以及垃圾回收原理)</div></div><div class="info-2"><div class="info-item-1">K8s-kubelet(Cgroup资源隔离以及垃圾回收原理) 基于1.25  什么是Cgroup资源隔离kubelet基于cgroup限制Pod资源使用。cgroup是Linux内核的一个重要功能，用来限制、控制和分离一个进程组的资源（CPU、内存、磁盘I&#x2F;O） kubelet在创建Pod时，会将其配置的cgroups parent目录传递给容器运行时，使容器运行时创建的进程都会限制到kubelet配置父级cgroup之下。  kubelet负责维护Pod、QoS、Node级别的cgroup配置 Container级别的cgroup直接交给容器运行时实现  cgroup的层级结构 kubelet采用了四级cgroups层级架构存储  Node Level cgroup 为了保证系统运行的稳定性，kubelet支持为系统守护进程预留资源，避免Pod占用整个系统资源，造成系统卡死或者崩溃。  默认情况下，kube-reserved和system-reserved不会启用。 但是启用之后，需要注意守护进程添加了cgroup之后，可能导致配置的上限太小，导致守护进程资源不足退...</div></div></div></a><a class="pagination-related" href="/2024/12/13/cloud/k8s/kubelet/K8s-kubelet(%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B)/" title="K8s-kubelet(Overview)"><img class="cover" src="/img/k8sLogo.png" onerror="onerror=null;src='/img/404.png'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">K8s-kubelet(Overview)</div></div><div class="info-2"><div class="info-item-1">K8s-kubelet(Overview) 基于1.25  kubelete的启动流程主要分为5个步骤：  Cobra命令参数解析 运行环境检测和设置 Kubelet对象实例化 启动kubelet主服务 启动HTTP Server服务和gRPC Server   Cobra命令行参数解析 Ref:https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/cmd/kubelet/app/server.go#L123 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/12/16/cloud/k8s/kubelet/K8s-kubelet(HTTP%E6%9C%8D%E5%8A%A1%E6%8E%A5%E5%8F%A3)/" title="K8s-kubelet(HTTP服务接口)"><img class="cover" src="/img/k8sLogo.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-16</div><div class="info-item-2">K8s-kubelet(HTTP服务接口)</div></div><div class="info-2"><div class="info-item-1">K8s-kubelet(HTTP服务接口) 基于1.25  kubelet通过HTTP Server对外暴露API，为了确保接口安全，kubelet按照安全等级从低到高顺序支持3种HTTP Server，分别是healthz server、readonly server和kubelet core server    一级类目 二级类目 Path路径 描述    Default Handlerers healthz &#x2F;healthz 检查kubelet是否健康，重点检查syncLoop是否持续在规定时间内完成。检查syncLoop四因为其他组件故障会间接导致syncLoop不能执行成功   Default Handlerers pods &#x2F;pods 读取当前节点运行的Pod列表（通过PodManager获取）   Default Handlerers stats &#x2F;stats&#x2F;summary 读取资源使用状态   Default Handlerers metrics &#x2F;metrics 读取kubelet监控指标数据   Defaul...</div></div></div></a><a class="pagination-related" href="/2024/12/15/cloud/k8s/kubelet/K8s-kubelet(PLEG%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86)/" title="K8s-kubelet(PLEG核心原理)"><img class="cover" src="/img/k8sLogo.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-15</div><div class="info-item-2">K8s-kubelet(PLEG核心原理)</div></div><div class="info-2"><div class="info-item-1">K8s-kubelet(PLEG核心原理) 基于1.25  PLEG是kubelet的一个重要组件，负责监控kubelet管理的节点运行的Pod的生命周期，并生成于生命周期相关的事件 PLEG产生原因在K8s中，kubelet负责维护和管理每个节点上的Pod，不断的调谐Pod的状态以使得符合Spec。  为了实现这个目标，kubelet同时需要支持对Pod Spec和Container Status 的事件监听。对于前者kubelet通过watch不同源的对PodSpec事件实现，对于后者，PLEG之前，不断需要Pod处理协程不断的周期性拉取最新状态，尝试了大量轮询压力。 在kubeletv1.2.0版本引入了PLEG，目标是改善kubelet的可拓展性 减少不必要的处理操作（当状态为发生变化时，不执行无效的调谐操作） 减少对底层容器运行的并发请求，以减轻容器运行时的压力    PLEG架构设计PLEG主要包含俩个核心工作，一是感受容器变化，生成Pod事件，俩是维持一份最新的Pod Status Cache数据供其他组件读取。   kubelet同时接收俩个方向的事件，Pod S...</div></div></div></a><a class="pagination-related" href="/2024/12/14/cloud/k8s/kubelet/K8s-kubelet(Cgroup%E8%B5%84%E6%BA%90%E9%9A%94%E7%A6%BB%E4%BB%A5%E5%8F%8A%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%8E%9F%E7%90%86)/" title="K8s-kubelet(Cgroup资源隔离以及垃圾回收原理)"><img class="cover" src="/img/k8sLogo.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-14</div><div class="info-item-2">K8s-kubelet(Cgroup资源隔离以及垃圾回收原理)</div></div><div class="info-2"><div class="info-item-1">K8s-kubelet(Cgroup资源隔离以及垃圾回收原理) 基于1.25  什么是Cgroup资源隔离kubelet基于cgroup限制Pod资源使用。cgroup是Linux内核的一个重要功能，用来限制、控制和分离一个进程组的资源（CPU、内存、磁盘I&#x2F;O） kubelet在创建Pod时，会将其配置的cgroups parent目录传递给容器运行时，使容器运行时创建的进程都会限制到kubelet配置父级cgroup之下。  kubelet负责维护Pod、QoS、Node级别的cgroup配置 Container级别的cgroup直接交给容器运行时实现  cgroup的层级结构 kubelet采用了四级cgroups层级架构存储  Node Level cgroup 为了保证系统运行的稳定性，kubelet支持为系统守护进程预留资源，避免Pod占用整个系统资源，造成系统卡死或者崩溃。  默认情况下，kube-reserved和system-reserved不会启用。 但是启用之后，需要注意守护进程添加了cgroup之后，可能导致配置的上限太小，导致守护进程资源不足退...</div></div></div></a><a class="pagination-related" href="/2024/12/13/cloud/k8s/kubelet/K8s-kubelet(%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B)/" title="K8s-kubelet(Overview)"><img class="cover" src="/img/k8sLogo.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-13</div><div class="info-item-2">K8s-kubelet(Overview)</div></div><div class="info-2"><div class="info-item-1">K8s-kubelet(Overview) 基于1.25  kubelete的启动流程主要分为5个步骤：  Cobra命令参数解析 运行环境检测和设置 Kubelet对象实例化 启动kubelet主服务 启动HTTP Server服务和gRPC Server   Cobra命令行参数解析 Ref:https://github.com/kubernetes/kubernetes/blob/88e994f6bf8fc88114c5b733e09afea339bea66d/cmd/kubelet/app/server.go#L123 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211...</div></div></div></a><a class="pagination-related" href="/2024/12/12/cloud/k8s/kubelet/K8s-kubelet(Overview)/" title="K8s-kubelet(Overview)"><img class="cover" src="/img/k8sLogo.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-12</div><div class="info-item-2">K8s-kubelet(Overview)</div></div><div class="info-2"><div class="info-item-1">K8s-kubelet(Overview) 基于1.25  kubelet是K8s中最重要的节点代理程序，运行在集群的每个节点上。  能够自动将节点注册到集群 将节点上、Pod运行状态和资源使用情况周期性上报到控制平面 同时接受控制平面发送到工作任务、启动停止容器、维护管理Pod 也包含对cAdvusor资源用量监控、容器和镜像垃圾回收  kubelet架构设计kubelet整体架构采用了基于事件的处理模型，通过syncLoop和不断调谐Podtatus和PodSpec差距 PodSpec主要来源自三个来源，kube-apiserver、file和HTTP。  file和HTTP主要用于发现Static类型的Pod kubelet默认每隔20s执行一次检测   PodStatus实际状态主要是通过PLEG周期性扫描冗余运行时的运行状态获取。 PLEG每隔1s，从容器运行时获取Pod和Container信息，并于本地缓存进行对比，发生变更的时候，生成PLEG事件，并且发送给事件订阅者触发执行事件处理程序。  默认，当产生PLEG事件，kubelet会执行sync调谐 kubelet...</div></div></div></a><a class="pagination-related" href="/2025/03/15/cloud/k8s/job/K8sController-Job(%E6%89%B9%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1)/" title="K8sController-Job(批处理任务)"><img class="cover" src="/img/k8sLogo.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-15</div><div class="info-item-2">K8sController-Job(批处理任务)</div></div><div class="info-2"><div class="info-item-1">K8sController-Job(批处理任务) 基于K8s 1.31  主要配置和工作机制123456789101112131415161718192021222324252627282930313233343536apiVersion: batch/v1kind: Jobmetadata:  name: hellospec:  # 可以并行任务数量，默认1  parallelism: 3  completions: 3  # Pod完成模式，NonIndexed（数量达到completions推出，默认），Indexed  # Indexed模式：会被设置为Pod服务名  # - 设置Pod名称：&lt;Job Name&gt;-&lt;索引序号&gt;-&lt;随机字符串&gt;  # - 设置Annotation &quot;batch.kubernetes.io/job-completion-index&quot;: &lt;索引序号&gt;  # - 设置Label &quot;batch.kubernetes.io/job-completion-index&quot...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Joohwan.</div><div class="author-info-description">该知道的都知道，不知道的慢慢了解</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">245</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">75</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">59</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/piwriw"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/piwriw" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:piwriw@163.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget"><div class="item-headline"><i class="iconfont icat-visitor"></i><span>来访者</span></div><div class="item-content"><div id="welcome-info"></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#K8s-kubelet-Pod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">K8s-kubelet(Pod生命周期管理)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CRI"><span class="toc-number">1.1.</span> <span class="toc-text">CRI</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">Pod启动流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#syncLoop%E7%9B%91%E5%90%AC%E5%88%B0Pod%E5%88%9B%E5%BB%BA%E4%BA%8B%E4%BB%B6%EF%BC%8C%E8%A7%A6%E5%8F%91%E6%89%A7%E8%A1%8CHandlerPodAdditions-Handler"><span class="toc-number">1.2.1.</span> <span class="toc-text">syncLoop监听到Pod创建事件，触发执行HandlerPodAdditions Handler</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#podWorkers%E6%94%B6%E5%88%B0Update%E4%BA%8B%E4%BB%B6%EF%BC%8C%E9%87%87%E7%94%A8%E7%8B%AC%E7%AB%8B%E5%8D%8F%E7%A8%8B%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8syncPod%E6%9D%A5%E5%A4%84%E7%90%86"><span class="toc-number">1.2.2.</span> <span class="toc-text">podWorkers收到Update事件，采用独立协程异步调用syncPod来处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%AE%B9%E5%99%A8%E5%88%9B%E5%BB%BA%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C-%E5%8C%85%E6%8B%AC%E6%A3%80%E6%9F%A5%E7%BD%91%E7%BB%9C%E3%80%81%E8%AE%BE%E7%BD%AEcgroup%E3%80%81%E6%8C%82%E8%BD%BD%E7%A3%81%E7%9B%98%E7%AD%89"><span class="toc-number">1.2.3.</span> <span class="toc-text">执行容器创建准备工作(包括检查网络、设置cgroup、挂载磁盘等)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E7%94%A8CRI%E5%88%9B%E5%BB%BASandbox%E9%9A%94%E7%A6%BB%E7%8E%AF%E5%A2%83%EF%BC%88%E5%8C%85%E5%90%AB%E8%B0%83%E7%94%A8CNI%E8%AE%BE%E7%BD%AE%E7%BD%91%E7%BB%9C%EF%BC%89"><span class="toc-number">1.2.4.</span> <span class="toc-text">调用CRI创建Sandbox隔离环境（包含调用CNI设置网络）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E7%94%A8CRI%E5%88%9B%E5%BB%BA%E6%99%AE%E9%80%9A%E5%AE%B9%E5%99%A8"><span class="toc-number">1.2.5.</span> <span class="toc-text">调用CRI创建普通容器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pod%E9%A9%B1%E9%80%90%E6%B5%81%E7%A8%8B"><span class="toc-number">1.3.</span> <span class="toc-text">Pod驱逐流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Critical-Pod%E8%A2%AB%E8%B0%83%E5%BA%A6%E5%88%B0%E8%8A%82%E7%82%B9%EF%BC%8C%E5%9B%A0%E8%B5%84%E6%BA%90%E7%AB%9E%E4%BA%89%EF%BC%8C%E8%A7%A6%E5%8F%91%E5%AF%B9%E4%BD%8E%E6%9C%89%E4%BC%98%E5%85%88%E7%BA%A7%E7%9A%84Pod%E7%9A%84%E9%A9%B1%E9%80%90"><span class="toc-number">1.3.1.</span> <span class="toc-text">Critical Pod被调度到节点，因资源竞争，触发对低有优先级的Pod的驱逐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E8%8A%82%E7%82%B9%E8%B5%84%E6%BA%90%E7%B4%A7%E5%BC%A0%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E4%B8%BA%E4%BA%86%E4%BF%9D%E8%AF%81%E8%8A%82%E7%82%B9%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7%EF%BC%8C%E8%A7%A6%E5%8F%91%E5%AF%B9%E4%BD%8E%E4%BC%98%E5%85%88%E7%BA%A7%E7%9A%84Pod%E7%9A%84%E9%A9%B1%E9%80%90"><span class="toc-number">1.3.2.</span> <span class="toc-text">在节点资源紧张的时候，为了保证节点的稳定性，触发对低优先级的Pod的驱逐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A1%AC%E9%A9%B1%E9%80%90%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">硬驱逐相关参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AF%E9%A9%B1%E9%80%90%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">软驱逐相关参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%AC%E5%85%B1%E5%8F%82%E6%95%B0"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">公共参数</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/08/24/cloud/k8s/K8s%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97-%E5%AE%A2%E6%88%B7%E7%AB%AF/" title="K8s开发指南-客户端"><img src="/img/k8sLogo.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="K8s开发指南-客户端"/></a><div class="content"><a class="title" href="/2025/08/24/cloud/k8s/K8s%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97-%E5%AE%A2%E6%88%B7%E7%AB%AF/" title="K8s开发指南-客户端">K8s开发指南-客户端</a><time datetime="2025-08-24T04:57:55.000Z" title="发表于 2025-08-24 12:57:55">2025-08-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/23/cloud/k8s/K8s%E5%BC%80%E5%8F%91-API%E8%AF%A6%E8%A7%A3/" title="K8s开发-API详解"><img src="/img/k8sLogo.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="K8s开发-API详解"/></a><div class="content"><a class="title" href="/2025/08/23/cloud/k8s/K8s%E5%BC%80%E5%8F%91-API%E8%AF%A6%E8%A7%A3/" title="K8s开发-API详解">K8s开发-API详解</a><time datetime="2025-08-23T04:57:55.000Z" title="发表于 2025-08-23 12:57:55">2025-08-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/22/cloud/k8s/K8s%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6-%E6%8B%93%E5%B1%95%E8%AE%A4%E8%AF%81/" title="K8s认证机制-拓展认证"><img src="/img/k8sLogo.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="K8s认证机制-拓展认证"/></a><div class="content"><a class="title" href="/2025/08/22/cloud/k8s/K8s%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6-%E6%8B%93%E5%B1%95%E8%AE%A4%E8%AF%81/" title="K8s认证机制-拓展认证">K8s认证机制-拓展认证</a><time datetime="2025-08-22T04:57:55.000Z" title="发表于 2025-08-22 12:57:55">2025-08-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/26/cloud/prometheus/Prometheus-Rules%E5%91%8A%E8%AD%A6%E8%AF%84%E4%BC%B0/" title="Prometheus-Rules告警评估"><img src="/img/prometheus.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="Prometheus-Rules告警评估"/></a><div class="content"><a class="title" href="/2025/07/26/cloud/prometheus/Prometheus-Rules%E5%91%8A%E8%AD%A6%E8%AF%84%E4%BC%B0/" title="Prometheus-Rules告警评估">Prometheus-Rules告警评估</a><time datetime="2025-07-26T14:08:55.000Z" title="发表于 2025-07-26 22:08:55">2025-07-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/25/cloud/prometheus/Prometheus-Srape%E6%8C%87%E6%A0%87%E6%8A%93%E5%8F%96/" title="Prometheus-Scrape指标抓取"><img src="/img/prometheus.png" onerror="this.onerror=null;this.src='/img/404.png'" alt="Prometheus-Scrape指标抓取"/></a><div class="content"><a class="title" href="/2025/07/25/cloud/prometheus/Prometheus-Srape%E6%8C%87%E6%A0%87%E6%8A%93%E5%8F%96/" title="Prometheus-Scrape指标抓取">Prometheus-Scrape指标抓取</a><time datetime="2025-07-25T14:08:55.000Z" title="发表于 2025-07-25 22:08:55">2025-07-25</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2023 - 2025 By Joohwan.</span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://piwriw-twikoo-git-main-piwriw.vercel.app/',
      region: 'ap-shanghai',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://piwriw-twikoo-git-main-piwriw.vercel.app/',
      region: 'ap-shanghai',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start -->
  <script data-pjax src="undefined"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="undefined?piwriw";
            var git_color =undefined;
            var git_user ="piwriw";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px; display: flex; align-items: center; justify-content: center;"> <img src="https://ghchart.rshah.org/piwriw" alt="piwriw" style="width: 100%; height: auto; max-width: 100%;"> </div> ';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:undefined}@media screen and (max-width:650px) {#github_container{background-image:;min-height:undefined}}</style>
    <style>undefined</style><!-- hexo injector body_end end --></body></html>